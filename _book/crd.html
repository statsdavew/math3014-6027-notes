<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Completely randomised designs | MATH3014-6027 Design (and Analysis) of Experiments</title>
  <meta name="description" content="Lecture notes for the modules MATH3014 and MATH6027 at the University of Southampton" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Completely randomised designs | MATH3014-6027 Design (and Analysis) of Experiments" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Lecture notes for the modules MATH3014 and MATH6027 at the University of Southampton" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Completely randomised designs | MATH3014-6027 Design (and Analysis) of Experiments" />
  
  <meta name="twitter:description" content="Lecture notes for the modules MATH3014 and MATH6027 at the University of Southampton" />
  

<meta name="author" content="Dave Woods" />


<meta name="date" content="2022-03-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intro.html"/>
<link rel="next" href="blocking.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MATH3014-6027</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Motivation, introduction and revision</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#aims-of-experimentation-and-some-examples"><i class="fa fa-check"></i><b>1.2</b> Aims of experimentation and some examples</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#some-definitions"><i class="fa fa-check"></i><b>1.3</b> Some definitions</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#principles"><i class="fa fa-check"></i><b>1.4</b> Principles of experimentation</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#replication"><i class="fa fa-check"></i><b>1.4.1</b> Replication</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#randomisation"><i class="fa fa-check"></i><b>1.4.2</b> Randomisation</a></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#intro-blocking"><i class="fa fa-check"></i><b>1.4.3</b> Stratification (or blocking)</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#lin-model-rev"><i class="fa fa-check"></i><b>1.5</b> Revision on the linear model</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#variance-of-a-predictionfitted-value"><i class="fa fa-check"></i><b>1.5.1</b> Variance of a Prediction/Fitted Value</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#analysis-of-variance-and-r2-as-model-comparison"><i class="fa fa-check"></i><b>1.5.2</b> Analysis of Variance and R<span class="math inline">\(^{2}\)</span> as Model Comparison</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#exercises"><i class="fa fa-check"></i><b>1.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="crd.html"><a href="crd.html"><i class="fa fa-check"></i><b>2</b> Completely randomised designs</a>
<ul>
<li class="chapter" data-level="2.1" data-path="crd.html"><a href="crd.html#a-unit-treatment-linear-model"><i class="fa fa-check"></i><b>2.1</b> A unit-treatment linear model</a></li>
<li class="chapter" data-level="2.2" data-path="crd.html"><a href="crd.html#the-partitioned-linear-model"><i class="fa fa-check"></i><b>2.2</b> The partitioned linear model</a></li>
<li class="chapter" data-level="2.3" data-path="crd.html"><a href="crd.html#reduced-normal-equations-for-the-crd"><i class="fa fa-check"></i><b>2.3</b> Reduced normal equations for the CRD</a></li>
<li class="chapter" data-level="2.4" data-path="crd.html"><a href="crd.html#contrasts"><i class="fa fa-check"></i><b>2.4</b> Contrasts</a></li>
<li class="chapter" data-level="2.5" data-path="crd.html"><a href="crd.html#contrast-crd"><i class="fa fa-check"></i><b>2.5</b> Treatment contrast estimators in the CRD</a></li>
<li class="chapter" data-level="2.6" data-path="crd.html"><a href="crd.html#r-crd"><i class="fa fa-check"></i><b>2.6</b> Analysing CRDs in R</a></li>
<li class="chapter" data-level="2.7" data-path="crd.html"><a href="crd.html#multiple-comp"><i class="fa fa-check"></i><b>2.7</b> Multiple comparisons</a></li>
<li class="chapter" data-level="2.8" data-path="crd.html"><a href="crd.html#impact-of-design-choices-on-estimation"><i class="fa fa-check"></i><b>2.8</b> Impact of design choices on estimation</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="crd.html"><a href="crd.html#crd-opt-all"><i class="fa fa-check"></i><b>2.8.1</b> Optimal treatment allocation</a></li>
<li class="chapter" data-level="2.8.2" data-path="crd.html"><a href="crd.html#crd-size"><i class="fa fa-check"></i><b>2.8.2</b> Overall size of the experiment</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="crd.html"><a href="crd.html#exercises-1"><i class="fa fa-check"></i><b>2.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="blocking.html"><a href="blocking.html"><i class="fa fa-check"></i><b>3</b> Blocking</a>
<ul>
<li class="chapter" data-level="3.1" data-path="blocking.html"><a href="blocking.html#unit-block-treatment-model"><i class="fa fa-check"></i><b>3.1</b> Unit-block-treatment model</a></li>
<li class="chapter" data-level="3.2" data-path="blocking.html"><a href="blocking.html#normal-equations"><i class="fa fa-check"></i><b>3.2</b> Normal equations</a></li>
<li class="chapter" data-level="3.3" data-path="blocking.html"><a href="blocking.html#block-anova"><i class="fa fa-check"></i><b>3.3</b> Analysis of variance</a></li>
<li class="chapter" data-level="3.4" data-path="blocking.html"><a href="blocking.html#rcdb"><i class="fa fa-check"></i><b>3.4</b> Randomised complete block designs</a></li>
<li class="chapter" data-level="3.5" data-path="blocking.html"><a href="blocking.html#blocks-orthogonal"><i class="fa fa-check"></i><b>3.5</b> Orthogonal blocking</a></li>
<li class="chapter" data-level="3.6" data-path="blocking.html"><a href="blocking.html#balanced-incomplete-block-designs"><i class="fa fa-check"></i><b>3.6</b> Balanced incomplete block designs</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="blocking.html"><a href="blocking.html#construction-of-bibds"><i class="fa fa-check"></i><b>3.6.1</b> Construction of BIBDs</a></li>
<li class="chapter" data-level="3.6.2" data-path="blocking.html"><a href="blocking.html#reduced-normal-equations"><i class="fa fa-check"></i><b>3.6.2</b> Reduced normal equations</a></li>
<li class="chapter" data-level="3.6.3" data-path="blocking.html"><a href="blocking.html#estimation-and-inference"><i class="fa fa-check"></i><b>3.6.3</b> Estimation and inference</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="blocking.html"><a href="blocking.html#exercises-2"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="factorial.html"><a href="factorial.html"><i class="fa fa-check"></i><b>4</b> Factorial experiments</a>
<ul>
<li class="chapter" data-level="4.1" data-path="factorial.html"><a href="factorial.html#factorial-contrasts"><i class="fa fa-check"></i><b>4.1</b> Factorial contrasts</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="factorial.html"><a href="factorial.html#main-effects"><i class="fa fa-check"></i><b>4.1.1</b> Main effects</a></li>
<li class="chapter" data-level="4.1.2" data-path="factorial.html"><a href="factorial.html#interactions"><i class="fa fa-check"></i><b>4.1.2</b> Interactions</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="factorial.html"><a href="factorial.html#three-principles-for-factorial-effects"><i class="fa fa-check"></i><b>4.2</b> Three principles for factorial effects</a></li>
<li class="chapter" data-level="4.3" data-path="factorial.html"><a href="factorial.html#unreplicated-normal-plots"><i class="fa fa-check"></i><b>4.3</b> Normal effect plots for unreplicated factorial designs</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="factorial.html"><a href="factorial.html#lenths-method-for-approximate-hypothesis-testing"><i class="fa fa-check"></i><b>4.3.1</b> Lenth’s method for approximate hypothesis testing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="block-factorial.html"><a href="block-factorial.html"><i class="fa fa-check"></i><b>5</b> Blocking in factorial designs</a></li>
<li class="chapter" data-level="6" data-path="fractional-factorial.html"><a href="fractional-factorial.html"><i class="fa fa-check"></i><b>6</b> Fractional factorial designs</a></li>
<li class="chapter" data-level="7" data-path="response-surface-methodology.html"><a href="response-surface-methodology.html"><i class="fa fa-check"></i><b>7</b> Response surface methodology</a></li>
<li class="chapter" data-level="8" data-path="optimal-design-of-experiments.html"><a href="optimal-design-of-experiments.html"><i class="fa fa-check"></i><b>8</b> Optimal design of experiments</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH3014-6027 Design (and Analysis) of Experiments</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="crd" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Completely randomised designs</h1>
<p>The simplest form of experiment we will consider compares <span class="math inline">\(t\)</span> different <strong>unstructured</strong> treatments. By unstructured, we mean the treatments form a discrete collection, not related through the settings of other experimental features (compare with factorial experiments in Chapter <a href="factorial.html#factorial">4</a>). We also make the assumption that there are no restrictions in the randomisation of treatments to experimental units (compare with Chapter <a href="blocking.html#blocking">3</a> on blocking). A designs for such an experiment is therefore called a <strong>completely randomised design</strong> (CRD).</p>
<div class="example">
<p><span id="exm:one-way" class="example"><strong>Example 2.1  </strong></span>Pulp experiment <span class="citation">(<a href="#ref-WH2009" role="doc-biblioref">Wu and Hamada, 2009</a>, ch. 2)</span></p>
<p>In a paper pulping mill, an experiment was run to examine differences between the reflectance (brightness; ratio of amount of light leaving a target to the amount of light striking the target) of sheets of pulp made by <span class="math inline">\(t=4\)</span> operators. The data are given in Table <a href="crd.html#tab:pulp-expt-data">2.1</a> below.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="crd.html#cb8-1" aria-hidden="true" tabindex="-1"></a>pulp <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">operator =</span> <span class="fu">rep</span>(<span class="fu">factor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>), <span class="dv">5</span>),</span>
<span id="cb8-2"><a href="crd.html#cb8-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">repetition =</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="fu">rep</span>(<span class="dv">4</span>, <span class="dv">5</span>)), </span>
<span id="cb8-3"><a href="crd.html#cb8-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">reflectance =</span> <span class="fu">c</span>(<span class="fl">59.8</span>, <span class="fl">59.8</span>, <span class="fl">60.7</span>, <span class="fl">61.0</span>, <span class="fl">60.0</span>, <span class="fl">60.2</span>, <span class="fl">60.7</span>, <span class="fl">60.8</span>, </span>
<span id="cb8-4"><a href="crd.html#cb8-4" aria-hidden="true" tabindex="-1"></a>                                    <span class="fl">60.8</span>, <span class="fl">60.4</span>, <span class="fl">60.5</span>, <span class="fl">60.6</span>, <span class="fl">60.8</span>, <span class="fl">59.9</span>, <span class="fl">60.9</span>, <span class="fl">60.5</span>, <span class="fl">59.8</span>, <span class="fl">60.0</span>, <span class="fl">60.3</span>, <span class="fl">60.5</span>)</span>
<span id="cb8-5"><a href="crd.html#cb8-5" aria-hidden="true" tabindex="-1"></a>                     )</span>
<span id="cb8-6"><a href="crd.html#cb8-6" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(</span>
<span id="cb8-7"><a href="crd.html#cb8-7" aria-hidden="true" tabindex="-1"></a> tidyr<span class="sc">::</span><span class="fu">pivot_wider</span>(pulp, <span class="at">names_from =</span> operator, <span class="at">values_from =</span> reflectance)[, <span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb8-8"><a href="crd.html#cb8-8" aria-hidden="true" tabindex="-1"></a> <span class="at">col.names =</span> <span class="fu">paste</span>(<span class="st">&quot;Operator&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>),</span>
<span id="cb8-9"><a href="crd.html#cb8-9" aria-hidden="true" tabindex="-1"></a> <span class="at">caption =</span> <span class="st">&quot;Pulp experiment: reflectance values (unitless) from four different operators.&quot;</span></span>
<span id="cb8-10"><a href="crd.html#cb8-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<table>
<caption><span id="tab:pulp-expt-data">Table 2.1: </span>Pulp experiment: reflectance values (unitless) from four different operators.</caption>
<thead>
<tr class="header">
<th align="right">Operator 1</th>
<th align="right">Operator 2</th>
<th align="right">Operator 3</th>
<th align="right">Operator 4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">59.8</td>
<td align="right">59.8</td>
<td align="right">60.7</td>
<td align="right">61.0</td>
</tr>
<tr class="even">
<td align="right">60.0</td>
<td align="right">60.2</td>
<td align="right">60.7</td>
<td align="right">60.8</td>
</tr>
<tr class="odd">
<td align="right">60.8</td>
<td align="right">60.4</td>
<td align="right">60.5</td>
<td align="right">60.6</td>
</tr>
<tr class="even">
<td align="right">60.8</td>
<td align="right">59.9</td>
<td align="right">60.9</td>
<td align="right">60.5</td>
</tr>
<tr class="odd">
<td align="right">59.8</td>
<td align="right">60.0</td>
<td align="right">60.3</td>
<td align="right">60.5</td>
</tr>
</tbody>
</table>
<p>The experiment has one factor (operator) with four levels (sometimes called a one-way layout). The CRD employed has equal replication of each treatment (operator).</p>
<p>We can informally compare the responses from these four treatments graphically.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="crd.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(reflectance <span class="sc">~</span> operator, <span class="at">data =</span> pulp)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pulp-boxplot"></span>
<img src="bookdown_math3014-6027_files/figure-html/pulp-boxplot-1.png" alt="Pulp experiment: distributions of reflectance from the four operators." width="672" />
<p class="caption">
Figure 2.1: Pulp experiment: distributions of reflectance from the four operators.
</p>
</div>
<p>Figure <a href="crd.html#fig:pulp-boxplot">2.1</a> shows that, relative to the variation, there may be a difference in the mean response between treatments 1 and 2, and 3 and 4. In this chapter, we will see how to make this comparison formally using linear models, and to assess how the choice of design impacts our results.</p>
</div>
<p>Throughout this chapter we will assume the <span class="math inline">\(i\)</span>th treatment is applied to <span class="math inline">\(n_i\)</span> experimental unit, with total number of runs <span class="math inline">\(n = \sum_{i=1}^t n_i\)</span> in the experiment.</p>
<div id="a-unit-treatment-linear-model" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> A unit-treatment linear model</h2>
<p>An appropriate, and common, model to describe data from such experiments when the response is continuous is given by</p>
<p><span class="math display" id="eq:utm">\[\begin{equation}
y_{ij} = \mu + \tau_i + \varepsilon_{ij}\,, \quad i = 1, \ldots, t; j = 1, \ldots, n_i\,, 
\tag{2.1}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(y_{ij}\)</span> is the response from the <span class="math inline">\(j\)</span>th application of treatment <span class="math inline">\(i\)</span>, <span class="math inline">\(\mu\)</span> is a constant parameter, <span class="math inline">\(\tau_i\)</span> is the effect of the <span class="math inline">\(i\)</span>th treatment, and <span class="math inline">\(\varepsilon_{ij}\)</span> is the random individual effect from each experimental unit with <span class="math inline">\(E(\varepsilon_{ij})=0\)</span> and <span class="math inline">\(\mathrm{Var}(\varepsilon_{ij}) = \sigma^2\)</span>. All random errors are assumed independent and here we also assume <span class="math inline">\(\varepsilon_{ij} \sim N(0, \sigma^2)\)</span>.</p>
<p>Model <a href="crd.html#eq:utm">(2.1)</a> assumes that each treatment can be randomly allocated to one of the <span class="math inline">\(n\)</span> experimental units, and that the response observed is independent of the allocation of all the other treatments (the stable unit treatment value assumption or SUTVA).</p>
<p>Why is this model appropriate and commonly used? The expected response from the application of the <span class="math inline">\(i\)</span>th treatment is</p>
<p><span class="math display">\[
E(y_{ij}) = \mu + \tau_i\,.
\]</span>
The parameter <span class="math inline">\(\mu\)</span> can be thought of as representing the impact of many different features particular to <strong>this</strong> experiment but common to all units, and <span class="math inline">\(\tau_i\)</span> is the deviation due to applying treatment <span class="math inline">\(i\)</span>. From the applicable of two different hypothetical experiments, A and B, the expected response from treatment <span class="math inline">\(i\)</span> may be different due to a different overall mean. From experiment A:</p>
<p><span class="math display">\[
E(y_{ij}) = \mu_{\mathrm{A}} + \tau_i\,.
\]</span>
From experiment B:
<span class="math display">\[
E(y_{ij}) = \mu_{\mathrm{B}} + \tau_i\,.
\]</span>
But the <strong>difference</strong> between treatments <span class="math inline">\(k\)</span> and <span class="math inline">\(l\)</span> (<span class="math inline">\(k, l = 1,\ldots, t\)</span>)</p>
<p><span class="math display">\[\begin{align*}
E(y_{kj}) - E(y_{lj}) &amp; = \mu_A + \tau_k - \mu_A - \tau_l \\
&amp; = \tau_k - \tau_l\,,
\end{align*}\]</span></p>
<p>is constant across different experiments. This concept of <strong>comparison</strong> underpins most design of experiments, and will be applied throughout this module.</p>
</div>
<div id="the-partitioned-linear-model" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> The partitioned linear model</h2>
<p>In matrix form, we can write model <a href="crd.html#eq:utm">(2.1)</a> as</p>
<p><span class="math display">\[
\boldsymbol{y}= X_1\mu + X_2\boldsymbol{\tau}+ \boldsymbol{\varepsilon}\,,
\]</span>
where <span class="math inline">\(X_1 = \boldsymbol{1}_n\)</span>, the <span class="math inline">\(n\)</span>-vector with every entry equal to one,</p>
<p><span class="math display">\[
X_2 = \bigoplus_{i = 1}^t \boldsymbol{1}_{n_i} = \begin{bmatrix}
\boldsymbol{1}_{n_1} &amp; \boldsymbol{0}_{n_1} &amp; \cdots &amp;  \boldsymbol{0}_{n_1} \\
\boldsymbol{0}_{n_2} &amp; \boldsymbol{1}_{n_2} &amp; \cdots &amp;  \boldsymbol{0}_{n_2} \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
\boldsymbol{0}_{n_t} &amp; \boldsymbol{0}_{n_t} &amp; \cdots &amp;  \boldsymbol{1}_{n_t} \\
\end{bmatrix}\,,
\]</span>
with <span class="math inline">\(\bigoplus\)</span> denoting “direct sum”, <span class="math inline">\(\boldsymbol{0}_{n_i}\)</span> is the <span class="math inline">\(n_i\)</span>-vector with every entry equal to zero, <span class="math inline">\(\boldsymbol{\tau}= [\tau_1, \ldots, \tau_t]^{\mathrm{T}}\)</span> and <span class="math inline">\(\boldsymbol{\varepsilon}= [\varepsilon_{11}, \ldots, \varepsilon_{tn_t}]^{\mathrm{T}}\)</span>.</p>
<p>Why are we partitioning the model? Going back to our discussion of the role of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau_i\)</span>, it is clear that we not interested in estimating <span class="math inline">\(\mu\)</span>, which represents an experiment-specific contribution to the expected mean. Our only interest is in estimating the (differences between the) <span class="math inline">\(\tau_i\)</span>. Hence, we can treat <span class="math inline">\(\mu\)</span> as a nuisance parameter.</p>
<p>If we define <span class="math inline">\(X = [X_1\, \vert\, X_2]\)</span> and <span class="math inline">\(\boldsymbol{\beta}^{\mathrm{T}} = [\mu \vert \boldsymbol{\tau}^{\mathrm{T}}]\)</span>, we can write the usual least squares equations</p>
<p><span class="math display" id="eq:crd-ls">\[\begin{equation}
X^{\mathrm{T}}X\hat{\boldsymbol{\beta}} = X^{\mathrm{T}}\boldsymbol{y}
\tag{2.2}
\end{equation}\]</span>
as a system of two matrix equations</p>
<p><span class="math display">\[\begin{align*}
X_1^{\mathrm{T}}X_1\hat{\mu} + X_1^{\mathrm{T}}X_2\hat{\boldsymbol{\tau}} &amp; = X_1^{\mathrm{T}}\boldsymbol{y}\\
X_2^{\mathrm{T}}X_1\hat{\mu} + X_2^{\mathrm{T}}X_2\hat{\boldsymbol{\tau}} &amp; = X_2^{\mathrm{T}}\boldsymbol{y}\,. \\
\end{align*}\]</span></p>
<p>Assuming <span class="math inline">\((X_1^{\mathrm{T}}X_1)^{-1}\)</span> exists, which it does in this case, we can pre-multiply the first of these equations by <span class="math inline">\(X_2^{\mathrm{T}}X_1(X_1^{\mathrm{T}}X_1)^{-1}\)</span> and subtract it from the second equation to obtain</p>
<p><span class="math display">\[\begin{align*}
X_2^{\mathrm{T}}[I_n - X_1(X_1^{\mathrm{T}}X_1)^{-1}X_1^{\mathrm{T}}]X_1\hat{\mu} 
&amp; + X_2^{\mathrm{T}}[I_n - X_1(X_1^{\mathrm{T}}X_1)^{-1}X_1^{\mathrm{T}}]X_2\hat{\boldsymbol{\tau}} \\
&amp; = X_2^{\mathrm{T}}[I_n - X_1(X_1^{\mathrm{T}}X_1)^{-1}X_1^{\mathrm{T}}]\boldsymbol{y}\,.
\end{align*}\]</span></p>
<p>Writing <span class="math inline">\(H_1 = X_1(X_1^{\mathrm{T}}X_1)^{-1}X_1^{\mathrm{T}}\)</span>, we obtain</p>
<p><span class="math display" id="eq:almost-reduced">\[\begin{equation}
X_2^{\mathrm{T}}[I_n - H_1]X_1\hat{\mu} + X_2^{\mathrm{T}}[I_n - H_1]X_2\hat{\boldsymbol{\tau}} = X_2^{\mathrm{T}}[I_n - H_1]\boldsymbol{y}\,.
\tag{2.3}
\end{equation}\]</span>
The matrix <span class="math inline">\(H_1\)</span> is a “hat” matrix for a linear model containing only the term <span class="math inline">\(\mu\)</span>, and hence <span class="math inline">\(H_1X_1 = X_1\)</span> (see MATH2010 or STAT6123). Hence the first term in <a href="crd.html#eq:almost-reduced">(2.3)</a> is zero, and we obtain the <strong>reduced normal equations</strong> for <span class="math inline">\(\boldsymbol{\tau}\)</span>:</p>
<p><span class="math display" id="eq:crd-red-normal">\[\begin{equation}
X_2^{\mathrm{T}}[I_n - H_1]X_2\hat{\boldsymbol{\tau}} = X_2^{\mathrm{T}}[I_n - H_1]\boldsymbol{y}\,.
\tag{2.4}
\end{equation}\]</span></p>
<p>Note that the solutions from <a href="crd.html#eq:crd-red-normal">(2.4)</a> are not different from the solution to <span class="math inline">\(\hat{\boldsymbol{\tau}}\)</span> that would be obtained from solving <a href="crd.html#eq:crd-ls">(2.2)</a>; equation <a href="crd.html#eq:crd-red-normal">(2.4)</a> is simply a re-expression, where we have eliminated the nuisance parameter <span class="math inline">\(\mu\)</span>. This fact means that we rarely need to solve <a href="crd.html#eq:crd-red-normal">(2.4)</a> explicitly.</p>
<p>Recalling that for a hat matrix, <span class="math inline">\(I_n - H_1\)</span> is idempotent and symmetric (see MATH2010 or MATH6174), if we define</p>
<p><span class="math display">\[
X_{2|1} = (I_n - H_1)X_2\,,
\]</span>
then we can rewrite equation <a href="crd.html#eq:crd-red-normal">(2.4)</a> as</p>
<p><span class="math display" id="eq:rne">\[\begin{equation}
X_{2|1}^{\mathrm{T}}X_{2|1}\hat{\boldsymbol{\tau}} = X_{2|1}^{\mathrm{T}}\boldsymbol{y}\,, 
\tag{2.5}
\end{equation}\]</span></p>
<p>which are the normal equations for a linear model with expectation <span class="math inline">\(E(\boldsymbol{y}) = X_{2|1}\boldsymbol{\tau}\)</span>.</p>
</div>
<div id="reduced-normal-equations-for-the-crd" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Reduced normal equations for the CRD</h2>
<p>For the CRD discussed in this chapter, <span class="math inline">\(X_1^{\mathrm{T}}X_1 = n\)</span>, the total number of runs in the experiment<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>. Hence <span class="math inline">\((X_1^{\mathrm{T}}X_1)^{-1} = 1/n\)</span> and <span class="math inline">\(H_1 = \frac{1}{n}J_n\)</span>, with <span class="math inline">\(J_n\)</span> the <span class="math inline">\(n\times n\)</span> matrix with all entries equal to 1.</p>
<p>The adjusted model matrix then has the form</p>
<p><span class="math display" id="eq:crd-x21">\[\begin{align}
X_{2|1} &amp; = (I_n - H_1)X_2 \nonumber\\
&amp; = X_2 - \frac{1}{n}J_nX_2 \nonumber\\
&amp; = X_2 - \frac{1}{n}[n_1\boldsymbol{1}_n \vert \cdots \vert n_t\boldsymbol{1}_n]\,. \tag{2.6} 
\end{align}\]</span></p>
<p>That is, every column of <span class="math inline">\(X_2\)</span> has been adjusted by the subtraction of the column mean from each entry<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>. Also notice that each row of <span class="math inline">\(X_{2|1}\)</span> has a row-sum equal to zero (<span class="math inline">\(= 1 - \sum_{i=1}^tn_t/n\)</span>). Hence, <span class="math inline">\(X_{2|1}\)</span> is not of full column rank, and so the reduced normal equations do not have a unique solution<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>.</p>
<p>Although <a href="crd.html#eq:rne">(2.5)</a>, and hence, <a href="crd.html#eq:crd-ls">(2.2)</a>, have no unique solution<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>, it can be shown that both <span class="math inline">\(\widehat{X_{2|1}\boldsymbol{\tau}}\)</span> and <span class="math inline">\(\widehat{X\boldsymbol{\beta}}\)</span> have unique solutions. Hence fitted values <span class="math inline">\(\hat{\boldsymbol{y}} = \widehat{X\boldsymbol{\beta}}\)</span> and the residual sum of squares</p>
<p><span class="math display">\[
RSS = \left(\boldsymbol{y}- \widehat{X\boldsymbol{\beta}}\right)^{\mathrm{T}}\left(\boldsymbol{y}- \widehat{X\boldsymbol{\beta}}\right)
\]</span>
are both uniquely defined for any solution to <a href="crd.html#eq:crd-ls">(2.2)</a>. That is, every solution to the normal equations leads to the same fitted values and residual sum of squares.</p>
<p>In MATH2010 and STAT6123 we fitted models with categorical variables by defining a set of dummy variables and estimating a reduced model. Here, we will take a slightly different approach and study which combinations of parameters from <a href="crd.html#eq:utm">(2.1)</a> are estimable, and in particular which linear combinations of the treatment parameters <span class="math inline">\(\tau_i\)</span> we can estimate.</p>
<p>Let’s study equation <a href="crd.html#eq:rne">(2.5)</a> in more detail. We have</p>
<p><span class="math display">\[\begin{align*}
X^{\mathrm{T}}_{2|1}X_{2|1} &amp; = X_2^{\mathrm{T}}(I_n - H_1)X_2 \\
 &amp; = X_2^{\mathrm{T}}X_2 - X_2^{\mathrm{T}}H_1X_2 \\
 &amp; = \mathrm{diag}(\boldsymbol{n}) - \frac{1}{n}X_2^{\mathrm{T}}J_nX_2 \\
 &amp; = \mathrm{diag}(\boldsymbol{n}) - \frac{1}{n}\boldsymbol{n}\boldsymbol{n}^{\mathrm{T}}\,,
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{n}^{\mathrm{T}} = (n_1, \ldots, n_t)\)</span>. Hence, the reduced normal equations become</p>
<p><span class="math display" id="eq:crd-rne">\[\begin{align}
\left[\mathrm{diag}(\boldsymbol{n}) - \frac{1}{n}\boldsymbol{n}\boldsymbol{n}^{\mathrm{T}}\right]\hat{\boldsymbol{\tau}} &amp; = X_2^{\mathrm{T}}\boldsymbol{y}- \frac{1}{n}X_2^{\mathrm{T}}J_n\boldsymbol{y}\\
&amp; = X_2^{\mathrm{T}}\boldsymbol{y}- \boldsymbol{n}\bar{y}_{..}\,,
\tag{2.7}
\end{align}\]</span></p>
<p>where <span class="math inline">\(\bar{y}_{..} = \frac{1}{n}\sum_{i = 1}^t\sum_{j = 1}^{n_i} y_{ij}\)</span>, i.e. the overall average of the observations from the experiment.</p>
<p>From <a href="crd.html#eq:crd-rne">(2.7)</a> we obtain a system of <span class="math inline">\(t\)</span> equations, each having the form</p>
<p><span class="math display" id="eq:crd-irne">\[\begin{equation}
\hat{\tau}_i - \hat{\tau}_w = \bar{y}_{i.} - \bar{y}_{..}\,,
\tag{2.8}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\hat{\tau}_w = \frac{1}{n}\sum_{i=1}^tn_i\hat{\tau}_i\)</span> and <span class="math inline">\(\bar{y}_{i.} = \frac{1}{n_i}\sum_{j = 1}^{n_i}y_{ij}\)</span> <span class="math inline">\((i = 1, \ldots, t)\)</span>.</p>
<p>These <span class="math inline">\(t\)</span> equations are not independent; when multiplied by the <span class="math inline">\(n_i\)</span>, they sum to zero due to the linear dependency between the columns of <span class="math inline">\(X_{2|1}\)</span>. Hence, there is no unique solution to <span class="math inline">\(\hat{\boldsymbol{\tau}}\)</span> from equation <a href="crd.html#eq:crd-rne">(2.7)</a>. However, we can estimate certain linear combinations of the <span class="math inline">\(\tau_i\)</span>, called <em>contrasts</em>.</p>
</div>
<div id="contrasts" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Contrasts</h2>
<div class="definition">
<p><span id="def:contrast" class="definition"><strong>Definition 2.1  </strong></span>A treatment <strong>contrast</strong> is a linear combination <span class="math inline">\(\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}\)</span> with coefficient vector <span class="math inline">\(\boldsymbol{c}^{\mathrm{T}} = (c_1,\ldots, c_t)\)</span> such that <span class="math inline">\(\boldsymbol{c}^{\mathrm{T}}\boldsymbol{1} = 0\)</span>; that is, <span class="math inline">\(\sum_{i = 1}^t c_i = 0\)</span>.</p>
</div>
<p>For example, assume we have <span class="math inline">\(t = 3\)</span> treatments, then the following vectors <span class="math inline">\(\boldsymbol{c}\)</span> all define contrasts:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\boldsymbol{c}^{\mathrm{T}} = (1, -1, 0)\)</span>,</li>
<li><span class="math inline">\(\boldsymbol{c}^{\mathrm{T}} = (1, 0, -1)\)</span>,</li>
<li><span class="math inline">\(\boldsymbol{c}^{\mathrm{T}} = (0, 1, -1)\)</span>.</li>
</ol>
<p>In fact, they define all <span class="math inline">\({3\choose 2} = 3\)</span> pairwise comparisons between treatments. The following are also contrasts:</p>
<ol start="4" style="list-style-type: decimal">
<li><span class="math inline">\(\boldsymbol{c}^{\mathrm{T}} = (2, -1, -1)\)</span>,</li>
<li><span class="math inline">\(\boldsymbol{c}^{\mathrm{T}} = (0.5, -1, 0.5)\)</span>,</li>
</ol>
<p>each comparing the sum, or average, of expected responses from two treatments to the expected response from the remaining treatment.</p>
<p>The following are not contrasts, as <span class="math inline">\(\boldsymbol{c}^{\mathrm{T}}\boldsymbol{1} \ne 0\)</span>:</p>
<ol start="6" style="list-style-type: decimal">
<li><span class="math inline">\(\boldsymbol{c}^{\mathrm{T}} = (2, -1, 0)\)</span>,</li>
<li><span class="math inline">\(\boldsymbol{c}^{\mathrm{T}} = (1, 0, 0)\)</span>,</li>
</ol>
<p>with the final example once again demonstrating that we cannot estimate the individual <span class="math inline">\(\tau_i\)</span>.</p>
</div>
<div id="contrast-crd" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Treatment contrast estimators in the CRD</h2>
<p>We estimate a treatment contrast <span class="math inline">\(\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}\)</span> in the CRD via linear combinations of equations <a href="crd.html#eq:crd-irne">(2.8)</a>:</p>
<p><span class="math display">\[\begin{align*}
&amp; \sum_{i=1}^t c_i\hat{\tau}_i - \sum_{i=1}^tc_i\hat{\tau}_w = \sum_{i=1}^tc_i\bar{y}_{i.} - \sum_{i=1}^tc_i\bar{y}_{..} \\
\Rightarrow &amp; \sum_{i=1}^t c_i\hat{\tau}_i = \sum_{i=1}^tc_i\bar{y}_{i.}\,,
\end{align*}\]</span></p>
<p>as <span class="math inline">\(\sum_{i=1}^tc_i\hat{\tau}_w = \sum_{i=1}^tc_i\bar{y}_{..} = 0\)</span>, as <span class="math inline">\(\sum_{i=1}^tc_i = 0\)</span>. Hence, the unique estimator of the contrast <span class="math inline">\(\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}\)</span> has the form</p>
<p><span class="math display">\[
\widehat{\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}} = \sum_{i=1}^tc_i\bar{y}_{i.}\,.
\]</span>
That is, we estimate the contrast in the treatment effects by the corresponding contrast in the treatment means.</p>
<p>The variance of this estimator is straightforward to obtain:</p>
<p><span class="math display">\[\begin{align*}
\mathrm{var}\left(\widehat{\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}}\right) 
&amp; = \sum_{i=1}^tc_i^2\mathrm{var}(\bar{y}_{i.}) \\
&amp; = \sigma^2\sum_{i=1}^tc_i^2/n_i\,,
\end{align*}\]</span></p>
<p>as, under our model assumptions, each <span class="math inline">\(\bar{y}_{i.}\)</span> is an average of independent observations with variance <span class="math inline">\(\sigma^2\)</span>. Similarly, from model <a href="crd.html#eq:utm">(2.1)</a> we can derive the distribution of <span class="math inline">\(\widehat{\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}}\)</span> as</p>
<p><span class="math display">\[
\widehat{\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}} \sim N\left(\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}, \sigma^2\sum_{i=1}^tc_i^2/n_i\right)\,.
\]</span>
Confidence intervals and hypothesis tests for <span class="math inline">\(\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}\)</span> can be constructed/conducted using this distribution, e.g.</p>
<ul>
<li>a <span class="math inline">\(100(1-\frac{\alpha}{2})\)</span>% confidence interval:
<span class="math display">\[
 \boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau} \in \sum_{i=1}^tc_i\bar{y}_{i.} \pm t_{n-t, 1-\frac{\alpha}{2}}s\sqrt{\sum_{i=1}^tc_i^2/n_i}\,,
 \]</span></li>
</ul>
<p>where <span class="math inline">\(t_{n-t, 1-\frac{\alpha}{2}}\)</span> is the <span class="math inline">\(1-\frac{\alpha}{2}\)</span> quantile of a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-t\)</span> degrees of freedom and</p>
<p><span class="math display" id="eq:crd-s2">\[\begin{equation} 
s^2 = \frac{1}{n-t}\sum_{i=1}^t\sum_{j=1}^{n_i}(y_{ij} - \bar{y}_{i.})^2
\tag{2.9}
\end{equation}\]</span></p>
<p>is the estimate of <span class="math inline">\(\sigma^2\)</span>.</p>
<ul>
<li>the hypothesis <span class="math inline">\(H_0: \boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau} = 0\)</span> against the two-sided alternative <span class="math inline">\(H_1: \boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau} \ne 0\)</span> is rejected using a test of with confidence level <span class="math inline">\(1-\alpha/2\)</span> if</li>
</ul>
<p><span class="math display">\[
 \frac{|\sum_{i=1}^tc_i\bar{y}_{i.}|}{s\sqrt{\sum_{i=1}^tc_i^2/n_i}} &gt; t_{n-t, 1-\frac{\alpha}{2}}\,.
 \]</span></p>
</div>
<div id="r-crd" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> Analysing CRDs in R</h2>
<p>Let’s return to Example <a href="crd.html#exm:one-way">2.1</a>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="crd.html#cb10-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(</span>
<span id="cb10-2"><a href="crd.html#cb10-2" aria-hidden="true" tabindex="-1"></a> tidyr<span class="sc">::</span><span class="fu">pivot_wider</span>(pulp, <span class="at">names_from =</span> operator, <span class="at">values_from =</span> reflectance)[, <span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb10-3"><a href="crd.html#cb10-3" aria-hidden="true" tabindex="-1"></a> <span class="at">col.names =</span> <span class="fu">paste</span>(<span class="st">&quot;Operator&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>),</span>
<span id="cb10-4"><a href="crd.html#cb10-4" aria-hidden="true" tabindex="-1"></a> <span class="at">caption =</span> <span class="st">&quot;Pulp experiment: reflectance values (unitless) from four different operators.&quot;</span></span>
<span id="cb10-5"><a href="crd.html#cb10-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<table>
<caption><span id="tab:one-way-analysis">Table 2.2: </span>Pulp experiment: reflectance values (unitless) from four different operators.</caption>
<thead>
<tr class="header">
<th align="right">Operator 1</th>
<th align="right">Operator 2</th>
<th align="right">Operator 3</th>
<th align="right">Operator 4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">59.8</td>
<td align="right">59.8</td>
<td align="right">60.7</td>
<td align="right">61.0</td>
</tr>
<tr class="even">
<td align="right">60.0</td>
<td align="right">60.2</td>
<td align="right">60.7</td>
<td align="right">60.8</td>
</tr>
<tr class="odd">
<td align="right">60.8</td>
<td align="right">60.4</td>
<td align="right">60.5</td>
<td align="right">60.6</td>
</tr>
<tr class="even">
<td align="right">60.8</td>
<td align="right">59.9</td>
<td align="right">60.9</td>
<td align="right">60.5</td>
</tr>
<tr class="odd">
<td align="right">59.8</td>
<td align="right">60.0</td>
<td align="right">60.3</td>
<td align="right">60.5</td>
</tr>
</tbody>
</table>
<p>Clearly, we could directly calculate, and then compare, mean responses for each operator. However, there are (at least) two other ways we can proceed which use the fact we are fitting a linear model. These will be useful when we consider more complex models.</p>
<ol style="list-style-type: decimal">
<li><p>Using <code>pairwise.t.test</code>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="crd.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(pulp, </span>
<span id="cb11-2"><a href="crd.html#cb11-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">pairwise.t.test</span>(reflectance, operator, <span class="at">p.adjust.method =</span> <span class="st">&#39;none&#39;</span>))</span></code></pre></div>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  reflectance and operator 
## 
##   1     2     3    
## 2 0.396 -     -    
## 3 0.084 0.015 -    
## 4 0.049 0.008 0.775
## 
## P value adjustment method: none</code></pre>
<p>This function performs hypothesis tests for all pairwise treatment comparisons (with a default confidence level of 0.95). Here we can see that operators 1 and 4, 2 and 3, and 2 and 4 have statistically significant differences.</p></li>
<li><p>Using <code>lm</code> and the <code>emmeans</code> package.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="crd.html#cb13-1" aria-hidden="true" tabindex="-1"></a>pulp.lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(reflectance <span class="sc">~</span> operator, <span class="at">data =</span> pulp)</span>
<span id="cb13-2"><a href="crd.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(pulp.lm)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: reflectance
##           Df Sum Sq Mean Sq F value Pr(&gt;F)  
## operator   3   1.34   0.447     4.2  0.023 *
## Residuals 16   1.70   0.106                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="crd.html#cb15-1" aria-hidden="true" tabindex="-1"></a>pulp.emm <span class="ot">&lt;-</span> emmeans<span class="sc">::</span><span class="fu">emmeans</span>(pulp.lm, <span class="sc">~</span> operator)</span>
<span id="cb15-2"><a href="crd.html#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(pulp.emm, <span class="at">adjust =</span> <span class="st">&#39;none&#39;</span>)</span></code></pre></div>
<pre><code>##  contrast estimate    SE df t.ratio p.value
##  1 - 2        0.18 0.206 16   0.873  0.3955
##  1 - 3       -0.38 0.206 16  -1.843  0.0839
##  1 - 4       -0.44 0.206 16  -2.134  0.0486
##  2 - 3       -0.56 0.206 16  -2.716  0.0153
##  2 - 4       -0.62 0.206 16  -3.007  0.0083
##  3 - 4       -0.06 0.206 16  -0.291  0.7748</code></pre>
<p>Here, we have first fitted the linear model object. The <code>lm</code> function, by default, will have set up dummy variables with the first treatment (operator) as a baseline (see MATH2010 or STAT6123). We then take the intermediate step of calculating the ANOVA table for this experiment, and use an F-test to compare the model accounting for operator differences to the null model; there are differences between operators at the 5% significance level,</p>
<p>The choice of dummy variables in the linear model is unimportant; any set could be used<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a>, as in the next line we use the <code>emmeans</code> function (from the package of the same name) to specify that we are interested in estimating contrasts in the factor <code>operator</code> (which specifies our treatments in this experiment). Finally, the <code>pairs</code> command performs hypothesis tests for all pairwise comparisons between the four treatments. The results are the same as those obtained from using <code>pairwise.t.test</code>.</p></li>
</ol>
<p>Our preferred approach is using method 2 (<code>lm</code> and <code>emmeans</code>), for four main reasons:</p>
<ol style="list-style-type: lower-alpha">
<li><p>The function <code>contrasts</code> in the <code>emmeans</code> package can be used to estimate arbitrary treatment contrasts (see <code>help("contrast-methods")</code>).</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="crd.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># same as `pairs` above</span></span>
<span id="cb17-2"><a href="crd.html#cb17-2" aria-hidden="true" tabindex="-1"></a>emmeans<span class="sc">::</span><span class="fu">contrast</span>(pulp.emm, <span class="st">&quot;pairwise&quot;</span>, <span class="at">adjust =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<pre><code>##  contrast estimate    SE df t.ratio p.value
##  1 - 2        0.18 0.206 16   0.873  0.3955
##  1 - 3       -0.38 0.206 16  -1.843  0.0839
##  1 - 4       -0.44 0.206 16  -2.134  0.0486
##  2 - 3       -0.56 0.206 16  -2.716  0.0153
##  2 - 4       -0.62 0.206 16  -3.007  0.0083
##  3 - 4       -0.06 0.206 16  -0.291  0.7748</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="crd.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># estimating single contrast c = (1, -.5, -.5)</span></span>
<span id="cb19-2"><a href="crd.html#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># comparing operator 1 with operators 2 and 3</span></span>
<span id="cb19-3"><a href="crd.html#cb19-3" aria-hidden="true" tabindex="-1"></a>contrast1v23.emmc <span class="ot">&lt;-</span> <span class="cf">function</span>(levs) </span>
<span id="cb19-4"><a href="crd.html#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="st">&#39;t1 v avg t2 t3&#39;</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="sc">-</span>.<span class="dv">5</span>, <span class="sc">-</span>.<span class="dv">5</span>, <span class="dv">0</span>))</span>
<span id="cb19-5"><a href="crd.html#cb19-5" aria-hidden="true" tabindex="-1"></a>emmeans<span class="sc">::</span><span class="fu">contrast</span>(pulp.emm, <span class="st">&#39;contrast1v23&#39;</span>)</span></code></pre></div>
<pre><code>##  contrast       estimate    SE df t.ratio p.value
##  t1.v.avg.t2.t3     -0.1 0.179 16  -0.560  0.5832</code></pre></li>
<li><p>It more easily generalises to the more complicated models we will see in Chapter <a href="blocking.html#blocking">3</a>.</p></li>
<li><p>It explicitly acknowledges that we have fitted a linear model, and so encourages us to check the model assumptions (see <a href="#nap-black-ex">Exercise 3</a>).</p></li>
<li><p>It is straightfoward to apply adjustments for <a href="crd.html#multiple-comp">multiple comparisons</a>.</p></li>
</ol>
</div>
<div id="multiple-comp" class="section level2" number="2.7">
<h2><span class="header-section-number">2.7</span> Multiple comparisons</h2>
<p>When we perform hypothesis testing, we choose the critical region (i.e. the rule that decides if we reject <span class="math inline">\(H_0\)</span>) to control the probability of a type I error; that is, we control the probability of incorrectly rejecting <span class="math inline">\(H_0\)</span>. If we need to test multiple hypotheses, e.g. to test all pairwise differences, we need to consider the overall probability of incorrectly rejecting <strong>one or more</strong> null hypothesis. This is called the <strong>experiment-wise</strong> or <strong>family-wise</strong> error rate.</p>
<p>For Example <a href="crd.html#exm:one-way">2.1</a>, there are <span class="math inline">\({4 \choose 2} = 6\)</span> pairwise comparisons. Under the assumption that all tests are independent<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a>, assuming each individual test has type I error 0.05, the experiment-wise type I error rate is given by:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="crd.html#cb21-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb21-2"><a href="crd.html#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> (<span class="dv">1</span> <span class="sc">-</span> alpha)<span class="sc">^</span><span class="dv">6</span></span></code></pre></div>
<pre><code>## [1] 0.2649</code></pre>
<p>An experiment-wise error rate of 0.2649 is substantially greater than 0.05. Hence, we would expect to make many more type I errors than may be desirable. <a href="https://xkcd.com/882">xkcd</a> has a fun example:</p>
<p><img src="https://imgs.xkcd.com/comics/significant.png" width="75%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="crd.html#cb23-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb23-2"><a href="crd.html#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> (<span class="dv">1</span> <span class="sc">-</span> alpha)<span class="sc">^</span><span class="dv">20</span></span></code></pre></div>
<pre><code>## [1] 0.6415</code></pre>
<p>Therefore it is usually desirable to maintain some control of the experiment-wise type I error rate. We will consider two methods.</p>
<ol style="list-style-type: decimal">
<li><p>The <strong>Bonferroni method</strong>. An upper bound on the experiment-wise type I error rate for testing <span class="math inline">\(k\)</span> hypotheses can be shown to be</p>
<p><span class="math display">\[\begin{align*}
P(\mbox{wrongly reject at least one of } H_{0}^1, \ldots, H_{0}^k) = &amp;    P\left(\bigcup_{i=1}^{k}\{\mbox{wrongly reject } H_{0}^i\}\right) \\
&amp; \leq \sum_{i=1}^{k}\underbrace{P(\mbox{wrongly reject } H_{0}^i)}_{\leq \alpha} \\ 
&amp; \leq k\alpha\,.
\end{align*}\]</span></p>
<p>Hence a <em>conservative</em><a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a> adjustment for multiple comparisons is to test each hypothesis at size <span class="math inline">\(\alpha / k\)</span>, i.e. for the CRD compare to the quantile <span class="math inline">\(t_{n-t, 1-\frac{\alpha}{2k}}\)</span> (or multiply each individual p-value by <span class="math inline">\(k\)</span>).</p>
<p>For Example <a href="crd.html#exm:one-way">2.1</a>, we can test all pairwise comparisons, each at size <span class="math inline">\(\alpha/k\)</span> using the <code>adjustment</code> argument in <code>pairs</code>.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="crd.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(pulp.emm, <span class="at">adjust =</span> <span class="st">&#39;bonferroni&#39;</span>)</span></code></pre></div>
<pre><code>##  contrast estimate    SE df t.ratio p.value
##  1 - 2        0.18 0.206 16   0.873  1.0000
##  1 - 3       -0.38 0.206 16  -1.843  0.5034
##  1 - 4       -0.44 0.206 16  -2.134  0.2918
##  2 - 3       -0.56 0.206 16  -2.716  0.0915
##  2 - 4       -0.62 0.206 16  -3.007  0.0501
##  3 - 4       -0.06 0.206 16  -0.291  1.0000
## 
## P value adjustment: bonferroni method for 6 tests</code></pre>
<p>Now, only one comparison is significant at an experiment-wise type I error rate of <span class="math inline">\(\alpha = 0.05\)</span> (operators 2 and 4).</p></li>
<li><p><strong>Tukey’s method</strong>. An alternative approach that gives an exact experiment-wise error rate of <span class="math inline">\(100\alpha\)</span>% compares the <span class="math inline">\(t\)</span> statistic to a critical value from the studentised range distribution<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a>, given by <span class="math inline">\(\frac{1}{\sqrt{2}}q_{t, n-t, 1-\alpha}\)</span> with <span class="math inline">\(q_{t, n-t, 1-\alpha}\)</span> the <span class="math inline">\(1-\alpha\)</span> quantile from the studentised range distribution (available in <code>R</code> as <code>qtukey</code>).</p>
<p>For Example <a href="crd.html#exm:one-way">2.1</a>:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="crd.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(pulp.emm)</span></code></pre></div>
<pre><code>##  contrast estimate    SE df t.ratio p.value
##  1 - 2        0.18 0.206 16   0.873  0.8185
##  1 - 3       -0.38 0.206 16  -1.843  0.2903
##  1 - 4       -0.44 0.206 16  -2.134  0.1845
##  2 - 3       -0.56 0.206 16  -2.716  0.0658
##  2 - 4       -0.62 0.206 16  -3.007  0.0377
##  3 - 4       -0.06 0.206 16  -0.291  0.9911
## 
## P value adjustment: tukey method for comparing a family of 4 estimates</code></pre></li>
</ol>
<p>The default adjustment in the <code>pairs</code> function is the Tukey method. Comparing the p-values for each comparison using unadjusted t-tests, the Boneferroni and Tukey methods:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="crd.html#cb29-1" aria-hidden="true" tabindex="-1"></a>pairs.u <span class="ot">&lt;-</span> <span class="fu">pairs</span>(pulp.emm, <span class="at">adjust =</span> <span class="st">&#39;none&#39;</span>)</span>
<span id="cb29-2"><a href="crd.html#cb29-2" aria-hidden="true" tabindex="-1"></a>pairs.b <span class="ot">&lt;-</span> <span class="fu">pairs</span>(pulp.emm, <span class="at">adjust =</span> <span class="st">&#39;bonferroni&#39;</span>)</span>
<span id="cb29-3"><a href="crd.html#cb29-3" aria-hidden="true" tabindex="-1"></a>pairs.t <span class="ot">&lt;-</span> <span class="fu">pairs</span>(pulp.emm)</span>
<span id="cb29-4"><a href="crd.html#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="fu">transform</span>(pairs.b)[, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>], <span class="at">Bonf.p.value =</span> <span class="fu">transform</span>(pairs.b)[, <span class="dv">6</span>], <span class="at">Tukey.p.value =</span> <span class="fu">transform</span>(pairs.t)[, <span class="dv">6</span>], <span class="at">unadjust.p.value =</span> <span class="fu">transform</span>(pairs.u)[, <span class="dv">6</span>])</span></code></pre></div>
<pre><code>##   contrast estimate     SE df t.ratio Bonf.p.value Tukey.p.value
## 1    1 - 2     0.18 0.2062 16  0.8731      1.00000       0.81854
## 2    1 - 3    -0.38 0.2062 16 -1.8433      0.50336       0.29030
## 3    1 - 4    -0.44 0.2062 16 -2.1343      0.29182       0.18448
## 4    2 - 3    -0.56 0.2062 16 -2.7164      0.09150       0.06579
## 5    2 - 4    -0.62 0.2062 16 -3.0074      0.05009       0.03767
## 6    3 - 4    -0.06 0.2062 16 -0.2910      1.00000       0.99108
##   unadjust.p.value
## 1         0.395509
## 2         0.083893
## 3         0.048637
## 4         0.015251
## 5         0.008349
## 6         0.774758</code></pre>
<p>Although the decision on which hypotheses to reject (comparson 2 - 4) is the same here for both methods, the p-values from the Bonferroni method are all larger, reflecting its more conservative nature.</p>
</div>
<div id="impact-of-design-choices-on-estimation" class="section level2" number="2.8">
<h2><span class="header-section-number">2.8</span> Impact of design choices on estimation</h2>
<p>Recall from Section <a href="crd.html#contrast-crd">2.5</a> that the width of a confidence interval for a contrast <span class="math inline">\(\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}\)</span> is given by <span class="math inline">\(2t_{n-t, 1-\frac{\alpha}{2}}s\sqrt{\sum_{i=1}^tc_i^2/n_i}\)</span>. The expectation of the square of this quantity is given by</p>
<p><span class="math display">\[
4t^2_{n-t, 1-\frac{\alpha}{2}}\sigma^2\sum_{i=1}^tc_i^2/n_i\,,
\]</span>
as <span class="math inline">\(E(s^2) = \sigma^2\)</span>. It is intuitive that a good design should have small values of the square root of this quantity (divided by <span class="math inline">\(2\sigma\)</span>),</p>
<p><span class="math display">\[
t_{n-t, 1-\frac{\alpha}{2}}\sqrt{\sum_{i=1}^tc_i^2/n_i}\,,
\]</span>
which can be achieved either by increasing <span class="math inline">\(n\)</span>, and hence reducing the size of the <span class="math inline">\(t\)</span>-quantile, or for choice of the <span class="math inline">\(n_i\)</span> for a fixed <span class="math inline">\(n\)</span>, i.e. through choice of replication of each treatment.</p>
<div id="crd-opt-all" class="section level3" number="2.8.1">
<h3><span class="header-section-number">2.8.1</span> Optimal treatment allocation</h3>
<p>It is quite common that although the total number, <span class="math inline">\(n\)</span>, of runs in the experiment may be fixed, the number <span class="math inline">\(n_1, n_2, \ldots, n_t\)</span> applied to the different treatments is under the experimenter’s control. Choosing <span class="math inline">\(n_1, n_2\)</span> subject to <span class="math inline">\(n_1+n_2 = n\)</span> was the first <strong>optimal design</strong> problem we encountered in Chapter <a href="intro.html#intro">1</a>.</p>
<p>Assume interest lies in estimating the set of <span class="math inline">\(p\)</span> contrasts <span class="math inline">\(\boldsymbol{c}_1^{\mathrm{T}}\boldsymbol{\tau}, \ldots, \boldsymbol{c}_p^{\mathrm{T}}\boldsymbol{\tau}\)</span>, with <span class="math inline">\(\boldsymbol{c}_l^{\mathrm{T}} = (c_{l1}, \ldots, c_{lt})\)</span>. One useful measure of the overall quality of the estimators of these <span class="math inline">\(p\)</span> contrasts is the average variance, given by</p>
<p><span class="math display">\[
\sigma^2\sum_{l=1}^p\sum_{i=1}^tc_{li}^2/n_i\,.
\]</span>
So we will minimise this variance by allocating larger values of <span class="math inline">\(n_i\)</span> to the treatments with correspondingly larger values of the contrast coefficients <span class="math inline">\(c_{li}\)</span>. Therefore an approach to optimal allocation is to choose <span class="math inline">\(\boldsymbol{n} = (n_1, \ldots, n_t)^{\mathrm{T}}\)</span> so as to</p>
<p><span class="math display" id="eq:opt-all">\[\begin{equation}
\mbox{minimise} \quad \phi(\boldsymbol{n}) = \sum_{l=1}^p\sum_{i=1}^tc_{li}^2/n_i\,\qquad \mbox{subject to} \quad \sum_{i=1}^tn_i = n\,.
\tag{2.10}
\end{equation}\]</span></p>
<p>This is a discrete optimisation problem (the <span class="math inline">\(n_i\)</span> are integers). It is usually easier to solve the relaxed problem, where we allow continuous <span class="math inline">\(0\le n_i \le n\)</span>, and round the resulting solution to obtain integers. There is no guarantee that such a rounded allocation will actually be the optimal integer-valued solution, but it is usually fairly close.</p>
<p>To solve the continuous version of <a href="crd.html#eq:opt-all">(2.10)</a> we will use the method of Lagrange mutliplers, where we define the function</p>
<p><span class="math display">\[
h(\boldsymbol{n}, \lambda) = \phi(\boldsymbol{n}) + \lambda\left(\sum_{i=1}^tn_i - n\right)\,,
\]</span>
introducing the new scalar variable <span class="math inline">\(\lambda\)</span>, and solve the set of <span class="math inline">\(t+1\)</span> equations:</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial h}{\partial n_1} &amp; = 0 \\
\vdots &amp; \\
\frac{\partial h}{\partial n_t} &amp; = 0 \\
\frac{\partial h}{\partial \lambda} &amp; = 0\,.
\end{align*}\]</span></p>
<p>In this case, we have</p>
<p><span class="math display" id="eq:lm-ni">\[\begin{equation}
\frac{\partial h}{\partial n_i} = -\sum_{l=1}^pc_{li}^2/n_i^2 + \lambda = 0\,,\quad i=1,\ldots t,
\tag{2.11}
\end{equation}\]</span>
and
<span class="math display">\[
\frac{\partial h}{\partial \lambda} = \sum_{i=1}^t n_i - n = 0\,.
\]</span>
This last equation ensures <span class="math inline">\(\sum_{i=1}^tn_i = n\)</span>. From the <span class="math inline">\(t\)</span> equations described by <a href="crd.html#eq:lm-ni">(2.11)</a>, we get</p>
<p><span class="math display">\[
n_i \propto \sqrt{\sum_{l=1}^pc_{li}^2}
\]</span>
We don’t need to explicitly solve for <span class="math inline">\(\lambda\)</span> to find the normalising constant for each <span class="math inline">\(n_i\)</span>. As we know <span class="math inline">\(\sum_{i=1}^tn_i = n\)</span>, we obtain,</p>
<p><span class="math display" id="eq:opt-ni">\[\begin{equation}
n_i = \frac{\sqrt{\sum_{l=1}^pc_{li}^2}}{\sum_{i=1}^t\sqrt{\sum_{l=1}^pc_{li}^2}}n\,.
\tag{2.12}
\end{equation}\]</span></p>
<p>Let’s return to Example <a href="crd.html#exm:one-way">2.1</a> and calculate the optimal allocations under two different sets of contrasts. First, we define an <code>R</code> function for calculating <a href="crd.html#eq:opt-ni">(2.12)</a>.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="crd.html#cb31-1" aria-hidden="true" tabindex="-1"></a>opt_ni <span class="ot">&lt;-</span> <span class="cf">function</span>(C, n) {</span>
<span id="cb31-2"><a href="crd.html#cb31-2" aria-hidden="true" tabindex="-1"></a>  CtC <span class="ot">&lt;-</span> <span class="fu">t</span>(C) <span class="sc">%*%</span> C</span>
<span id="cb31-3"><a href="crd.html#cb31-3" aria-hidden="true" tabindex="-1"></a>  n <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(CtC)) <span class="sc">/</span> <span class="fu">sum</span>(<span class="fu">sqrt</span>(<span class="fu">diag</span>(CtC)))</span>
<span id="cb31-4"><a href="crd.html#cb31-4" aria-hidden="true" tabindex="-1"></a>} </span></code></pre></div>
<p>Checking that the function <code>opt-ni</code> matches <a href="crd.html#eq:opt-ni">(2.12)</a> is left as an exercise.</p>
<p>Consider two sets of contrasts:</p>
<ol style="list-style-type: decimal">
<li><p>All pairwise comparisons between the four treatments
<span class="math display">\[\begin{align*}
c_1 &amp; = (-1, 1, 0, 0) \\
c_2 &amp; = (-1, 0, 1, 0) \\
c_3 &amp; = (-1, 0, 0, 1) \\
c_4 &amp; = (0, -1, 1, 0) \\
c_5 &amp; = (0, -1, 0, 1) \\
c_6 &amp; = (0, 0, -1, 1)\,.
\end{align*}\]</span></p>
<p>Calculating <a href="crd.html#eq:opt-ni">(2.12)</a>, we obtain</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="crd.html#cb32-1" aria-hidden="true" tabindex="-1"></a>C <span class="ot">&lt;-</span> <span class="fu">matrix</span>(</span>
<span id="cb32-2"><a href="crd.html#cb32-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(</span>
<span id="cb32-3"><a href="crd.html#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>,</span>
<span id="cb32-4"><a href="crd.html#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>,</span>
<span id="cb32-5"><a href="crd.html#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>,</span>
<span id="cb32-6"><a href="crd.html#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>,</span>
<span id="cb32-7"><a href="crd.html#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>,</span>
<span id="cb32-8"><a href="crd.html#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb32-9"><a href="crd.html#cb32-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrow =</span> <span class="dv">6</span>, <span class="at">byrow =</span> T</span>
<span id="cb32-10"><a href="crd.html#cb32-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-11"><a href="crd.html#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="fu">opt_ni</span>(C, <span class="dv">20</span>)</span></code></pre></div>
<pre><code>## [1] 5 5 5 5</code></pre>
<p>Hence confirming that equal replication of the treatments is optimal for minimising the average variance of estimators of the pairwise treatment differences.</p></li>
<li><p>If operator 4 is new to the mill, it may be desired to test their output to the average output from the other three operators, using a contrast with coefficients <span class="math inline">\(c = (1/3, 1/3, 1/3, -1)\)</span>. The allocation to minimise the variance of the corresponding estimator is given by:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="crd.html#cb34-1" aria-hidden="true" tabindex="-1"></a>C <span class="ot">&lt;-</span> <span class="fu">matrix</span>(</span>
<span id="cb34-2"><a href="crd.html#cb34-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">1</span>),</span>
<span id="cb34-3"><a href="crd.html#cb34-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrow =</span> <span class="dv">1</span></span>
<span id="cb34-4"><a href="crd.html#cb34-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-5"><a href="crd.html#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="fu">opt_ni</span>(C, <span class="dv">20</span>)</span></code></pre></div>
<pre><code>## [1]  3.333  3.333  3.333 10.000</code></pre>
<p>So the optimal allocation splits 10 units between operators 1-3, and allocates 10 units to operator 4. There is no exact integer rounding possible, so we will use <span class="math inline">\(n_1 = 4\)</span>, <span class="math inline">\(n_2=n_3 = 3\)</span>, <span class="math inline">\(n_4 = 10\)</span> and calculate the efficiency by comparing the variance of this allocation to that from the equally allocated design.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="crd.html#cb36-1" aria-hidden="true" tabindex="-1"></a>crd_var <span class="ot">&lt;-</span> <span class="cf">function</span>(C, n) {</span>
<span id="cb36-2"><a href="crd.html#cb36-2" aria-hidden="true" tabindex="-1"></a>  CtC <span class="ot">&lt;-</span> <span class="fu">t</span>(C) <span class="sc">%*%</span> C</span>
<span id="cb36-3"><a href="crd.html#cb36-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(<span class="fu">diag</span>(CtC) <span class="sc">/</span> n)</span>
<span id="cb36-4"><a href="crd.html#cb36-4" aria-hidden="true" tabindex="-1"></a>} </span>
<span id="cb36-5"><a href="crd.html#cb36-5" aria-hidden="true" tabindex="-1"></a>n_equal <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">5</span>, <span class="dv">4</span>)</span>
<span id="cb36-6"><a href="crd.html#cb36-6" aria-hidden="true" tabindex="-1"></a>n_opt <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">10</span>)</span>
<span id="cb36-7"><a href="crd.html#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="fu">crd_var</span>(C, n_opt) <span class="sc">/</span> <span class="fu">crd_var</span>(C, n_equal)</span></code></pre></div>
<pre><code>## [1] 0.7569</code></pre>
<p>So the efficiency of the equally allocated design for estimating this contrast is 75.69 %.</p></li>
</ol>
</div>
<div id="crd-size" class="section level3" number="2.8.2">
<h3><span class="header-section-number">2.8.2</span> Overall size of the experiment</h3>
<p>We can also consider the complementary question: suppose the proportion of runs that is to be allocated to each treatment has been fixed in advance, what size of experiment should be performed to meet the objectives? That is, given a fixed proportion, <span class="math inline">\(w_i\)</span>, of resource to be allocated to the <span class="math inline">\(i\)</span>th treatment, so that <span class="math inline">\(n_i = nw_i\)</span> units will be allocated to that treatment, what value of <span class="math inline">\(n\)</span> should be chosen?</p>
<p>One way of thinking about this question is to consider the ratio</p>
<p><span class="math display">\[\begin{align*}
\frac{|\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}|}{\sqrt{\mbox{Var}(\widehat{\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}})}} &amp; = \frac{|\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}|}{\sqrt{\frac{\sigma^2}{n} \sum_{i=1}^tc_i^2/w_i}} \\
&amp; = \sqrt{n}\frac{|\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}| / \sigma}{\sqrt{\sum_{i=1}^tc_i^2/w_i}}\,,
\end{align*}\]</span></p>
<p>which is analogous to the test statistic for <span class="math inline">\(H_0: \boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau} = 0\)</span>. For a given value of the signal-to-noise ratio <span class="math inline">\(d = |\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}| / \sigma\)</span>, we can choose <span class="math inline">\(n\)</span> to result in a specified value of <span class="math inline">\(T = |\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}| / \sqrt{\mbox{Var}(\widehat{\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}})}\)</span>:</p>
<p><span class="math display">\[
n = T^2\frac{\sum_{i=1}^t c_i^2/w_i}{d^2}\,.
\]</span>
Returning to Example <a href="crd.html#exm:one-way">2.1</a>, assume are testing a single pairwise comparison and that we require <span class="math inline">\(T = 3\)</span>, so that the null hypothesis would be comfortably rejected at the 5% level (cf 1.96 for a standard z-test). For equal allocation of the units to each treatment (<span class="math inline">\(w_1 = \cdots = w_4 = 1/4\)</span>) and a variety of different values of the signal-to-noise ratio <span class="math inline">\(d\)</span>, we obtained the following optimal experiment sizes:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="crd.html#cb38-1" aria-hidden="true" tabindex="-1"></a>opt_n <span class="ot">&lt;-</span> <span class="cf">function</span>(cv, prop, snr, target) target <span class="sc">^</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">c</span>(<span class="fu">t</span>(cv) <span class="sc">%*%</span> <span class="fu">diag</span>( <span class="dv">1</span> <span class="sc">/</span> prop) <span class="sc">%*%</span> cv) <span class="sc">/</span> snr <span class="sc">^</span> <span class="dv">2</span></span>
<span id="cb38-2"><a href="crd.html#cb38-2" aria-hidden="true" tabindex="-1"></a>cv <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb38-3"><a href="crd.html#cb38-3" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">4</span>, <span class="dv">4</span>)</span>
<span id="cb38-4"><a href="crd.html#cb38-4" aria-hidden="true" tabindex="-1"></a>snr <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">1.5</span>, <span class="dv">2</span>, <span class="fl">2.5</span>, <span class="dv">3</span>)</span>
<span id="cb38-5"><a href="crd.html#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="st">&#39;Signal-to-noise&#39;</span> <span class="ot">=</span> snr, <span class="st">&#39;n&#39;</span> <span class="ot">=</span> <span class="fu">opt_n</span>(cv, w, snr, <span class="dv">3</span>))</span></code></pre></div>
<pre><code>##      Signal-to-noise      n
## [1,]             0.5 288.00
## [2,]             1.0  72.00
## [3,]             1.5  32.00
## [4,]             2.0  18.00
## [5,]             2.5  11.52
## [6,]             3.0   8.00</code></pre>
<p>So, for example, to achieve <span class="math inline">\(T = 3\)</span> with a signal-to-noise ratio of <span class="math inline">\(d=0.5\)</span> requires <span class="math inline">\(n=288\)</span> runs. As would be expected, the number of runs required to achieve this value of <span class="math inline">\(T\)</span> decreases as the signal-to-noise ration increases. For <span class="math inline">\(d=3\)</span>, only a very small experiment with <span class="math inline">\(n=8\)</span> runs is needed.</p>
</div>
</div>
<div id="exercises-1" class="section level2" number="2.9">
<h2><span class="header-section-number">2.9</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><ol style="list-style-type: lower-alpha">
<li><p>For Example <a href="crd.html#exm:one-way">2.1</a>, calculate the mean response for each operator and show that the treatment differences and results from hypothesis tests using the results in Section <a href="crd.html#contrast-crd">2.5</a> are the same as those found in Section <a href="crd.html#r-crd">2.6</a> using <code>pairwise.t.test</code>, and <code>emmeans</code>.</p></li>
<li><p>Also check the results in Section <a href="crd.html#multiple-comp">2.7</a> by (i) adjusting individual p-values (for Bonferroni) and (ii) using the <code>qtukey</code> command.</p></li>
</ol></li>
</ol>
<details>
<summary>
<b>Solution</b>
</summary>
<p>As a reminder, the data from the experiment is as follows.</p>
<table>
<thead>
<tr class="header">
<th align="right">Operator 1</th>
<th align="right">Operator 2</th>
<th align="right">Operator 3</th>
<th align="right">Operator 4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">59.8</td>
<td align="right">59.8</td>
<td align="right">60.7</td>
<td align="right">61.0</td>
</tr>
<tr class="even">
<td align="right">60.0</td>
<td align="right">60.2</td>
<td align="right">60.7</td>
<td align="right">60.8</td>
</tr>
<tr class="odd">
<td align="right">60.8</td>
<td align="right">60.4</td>
<td align="right">60.5</td>
<td align="right">60.6</td>
</tr>
<tr class="even">
<td align="right">60.8</td>
<td align="right">59.9</td>
<td align="right">60.9</td>
<td align="right">60.5</td>
</tr>
<tr class="odd">
<td align="right">59.8</td>
<td align="right">60.0</td>
<td align="right">60.3</td>
<td align="right">60.5</td>
</tr>
</tbody>
</table>
<p>The mean response, and variance, from each treatment is given by</p>
<table>
<thead>
<tr class="header">
<th align="left">operator</th>
<th align="right">n_i</th>
<th align="right">mean</th>
<th align="right">variance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="right">5</td>
<td align="right">60.24</td>
<td align="right">0.268</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="right">5</td>
<td align="right">60.06</td>
<td align="right">0.058</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="right">5</td>
<td align="right">60.62</td>
<td align="right">0.052</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="right">5</td>
<td align="right">60.68</td>
<td align="right">0.047</td>
</tr>
</tbody>
</table>
<p>The sample variance, <span class="math inline">\(s^2 = 0.106\)</span>, from <a href="crd.html#eq:crd-s2">(2.9)</a>. As <span class="math inline">\(\sum_{i=1}^tc_i^2/n_i = \frac{2}{5}\)</span> for contrast vectors <span class="math inline">\(\boldsymbol{c}\)</span> corresponding to pairwise differences, the standard error of each pairwise difference is given by <span class="math inline">\(\sqrt{\frac{2s^2}{5}} = 0.206\)</span>. Hence, we can create a table of pairwise differences, standard errors and test statistics.</p>
<table>
<thead>
<tr class="header">
<th align="left">contrast</th>
<th align="right">estimate</th>
<th align="right">SE</th>
<th align="right">df</th>
<th align="right">t.ratio</th>
<th align="right">unadjust.p.value</th>
<th align="right">Bonferroni</th>
<th align="right">Tukey</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1 - 2</td>
<td align="right">0.18</td>
<td align="right">0.206</td>
<td align="right">16</td>
<td align="right">0.873</td>
<td align="right">0.396</td>
<td align="right">1.000</td>
<td align="right">0.819</td>
</tr>
<tr class="even">
<td align="left">1 - 3</td>
<td align="right">-0.38</td>
<td align="right">0.206</td>
<td align="right">16</td>
<td align="right">-1.843</td>
<td align="right">0.084</td>
<td align="right">0.503</td>
<td align="right">0.290</td>
</tr>
<tr class="odd">
<td align="left">1 - 4</td>
<td align="right">-0.44</td>
<td align="right">0.206</td>
<td align="right">16</td>
<td align="right">-2.134</td>
<td align="right">0.049</td>
<td align="right">0.292</td>
<td align="right">0.184</td>
</tr>
<tr class="even">
<td align="left">2 - 3</td>
<td align="right">-0.56</td>
<td align="right">0.206</td>
<td align="right">16</td>
<td align="right">-2.716</td>
<td align="right">0.015</td>
<td align="right">0.092</td>
<td align="right">0.066</td>
</tr>
<tr class="odd">
<td align="left">2 - 4</td>
<td align="right">-0.62</td>
<td align="right">0.206</td>
<td align="right">16</td>
<td align="right">-3.007</td>
<td align="right">0.008</td>
<td align="right">0.050</td>
<td align="right">0.038</td>
</tr>
<tr class="even">
<td align="left">3 - 4</td>
<td align="right">-0.06</td>
<td align="right">0.206</td>
<td align="right">16</td>
<td align="right">-0.291</td>
<td align="right">0.775</td>
<td align="right">1.000</td>
<td align="right">0.991</td>
</tr>
</tbody>
</table>
<p>Unadjusted p-values are obtained from the t-distribution, as twice the tail probabilities (<code>2 * (1 - pt(abs(t.ratio), 16))</code>). For Bonferroni, we simply multiply these p-values by <span class="math inline">\({t \choose 2} = 6\)</span>, and then take the minimum of this value and 1. For the Tukey method, we use <code>1 - ptukey(abs(t.ratio) * sqrt(2), 4, 16)</code> (see <code>?ptukey</code>).</p>
Alternatively, to test each hypothesis at the 5% level, we can compare each t.ratio to (i) <code>qt(0.975, 16) = 2.12</code> (unadjusted); (ii) <code>qt(1 - 0.025/6, 16) = 3.008</code> (Bonferroni); or (iii) <code>qtukey(0.95, 4, 16) / sqrt(2) = 2.861</code>.
</details>
<ol start="2" style="list-style-type: decimal">
<li><p> <span class="citation">(Adapted from <a href="#ref-WH2009" role="doc-biblioref">Wu and Hamada, 2009</a>)</span> The bioactivity of four different drugs <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, <span class="math inline">\(C\)</span> and <span class="math inline">\(D\)</span> for treating a particular illness was compared in a study and the following ANOVA table was given for the data:</p>
<table>
<thead>
<tr class="header">
<th align="left">Source</th>
<th align="center">Degrees of freedom</th>
<th align="center">Sums of squares</th>
<th align="center">Mean square</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Treatment</td>
<td align="center">3</td>
<td align="center">64.42</td>
<td align="center">21.47</td>
</tr>
<tr class="even">
<td align="left">Residual</td>
<td align="center">26</td>
<td align="center">62.12</td>
<td align="center">2.39</td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="center">29</td>
<td align="center">126.54</td>
<td align="center"></td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-roman">
<li><p>What considerations should be made when assigning drugs to patients, and why?</p></li>
<li><p>Use an <span class="math inline">\(F\)</span>-test to test at the 0.01 level the null hypothesis that the four drugs have the same bioactivity.</p></li>
<li><p>The average response from each treatment is as follows: <span class="math inline">\(\bar{y}_{A.}=66.10\)</span> (<span class="math inline">\(n_A=7\)</span> patients), <span class="math inline">\(\bar{y}_{B.}=65.75\)</span> (<span class="math inline">\(n_B=8\)</span>), <span class="math inline">\(\bar{y}_{C.} = 62.63\)</span> (<span class="math inline">\(n_C=9\)</span>), and <span class="math inline">\(\bar{y}_{D.}=63.85\)</span> (<span class="math inline">\(n_D=6\)</span>). Conduct hypothesis tests for all pairwise comparisons using the Bonferroni and Tukey methods for an experiment-wise error rate of 0.05.</p></li>
<li><p>In fact, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are brand-name drugs and <span class="math inline">\(C\)</span> and <span class="math inline">\(D\)</span> are generic drugs. Test the null hypothesis at the 5% level that brand-name and generic drugs have the same bioactivity.</p></li>
</ol></li>
</ol>
<details>
<summary>
<b>Solution</b>
</summary>
<ol style="list-style-type: lower-roman">
<li><p>Each patient should be randomly allocated to one of the drugs. This is to protect against possible bias from lurking variables, e.g. demographic variables or subjective bias from the study administrator (blinding the study can also help to protect against this).</p></li>
<li><p>Test statistic = (Treatment mean square)/(Residual mean square) = 21.47/2.39 = 8.98. Under <span class="math inline">\(H_0\)</span>: no difference in bioactivity between the drugs, the test statistic follows an <span class="math inline">\(F_{3,26}\)</span> distribution, which has a 1% critical value of <code>qf(0.99, 3, 26) = 4.6366</code>. Hence, we can reject <span class="math inline">\(H_0\)</span>.</p></li>
<li><p>For each difference, the test statistic has the form</p>
<p><span class="math display">\[
 \frac{|\bar{y}_{i.}-\bar{y}_{j.}|}{s\sqrt{\frac{1}{n_i}+\frac{1}{n_j}}}\,,
 \]</span></p>
<p>for <span class="math inline">\(i, j = A, B, C, D;\, i\ne j\)</span>. The treatment means and repetitions are given in the question (note that not all <span class="math inline">\(n_i\)</span> are equal). From the ANOVA table, we get <span class="math inline">\(s^2 = 62.12/26 = 2.389\)</span>. The following table summarises the differences between drugs:</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left"><span class="math inline">\(A-B\)</span></th>
<th align="left"><span class="math inline">\(A-C\)</span></th>
<th align="left"><span class="math inline">\(A-D\)</span></th>
<th align="left"><span class="math inline">\(B-C\)</span></th>
<th align="left"><span class="math inline">\(B-D\)</span></th>
<th align="left"><span class="math inline">\(C-D\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Abs. difference</td>
<td align="left">0.35</td>
<td align="left">3.47</td>
<td align="left">2.25</td>
<td align="left">3.12</td>
<td align="left">1.9</td>
<td align="left">1.22</td>
</tr>
<tr class="even">
<td align="left">Test statistic</td>
<td align="left">0.44</td>
<td align="left">4.45</td>
<td align="left">2.62</td>
<td align="left">4.15</td>
<td align="left">2.28</td>
<td align="left">1.50</td>
</tr>
</tbody>
</table>
<p>The Bonferroni critical value is <span class="math inline">\(t_{26, 1-0.05/12} = 3.5069\)</span>. The Tukey critical value is <span class="math inline">\(q_{4,26, 0.95}/\sqrt{2} = 2.7433\)</span> (available <code>R</code> as <code>qtukey(0.95, 4, 26) / sqrt(2)</code>). Hence under both methods, bioactivity of drugs <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span>, and <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>, are significantly different.</p></li>
<li><p>A suitable contrast has <span class="math inline">\(\boldsymbol{c} = (0.5, 0.5, -0.5, -0.5)\)</span>, with <span class="math inline">\(\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau} = (\tau_A + \tau_B) / 2 - (\tau_C + \tau_D) / 2\)</span> (the difference in average treatment effects).</p>
<p>An estimate for this contrast is given by <span class="math inline">\((\bar{y}_{A.} + \bar{y}_{B.}) / 2 - (\bar{y}_{C.} + \bar{y}_{D.}) / 2\)</span>, with variance</p>
<p><span class="math display">\[\mbox{Var}\left(\frac{1}{2}(\bar{y}_{A.}+\bar{y}_{B.}) - \frac{1}{2}(\bar{y}_{C.}+\bar{Y}_{D.})\right) = \frac{\sigma^2}{4}\left(\frac{1}{n_A} + \frac{1}{n_B} + \frac{1}{n_C} + \frac{1}{n_D}\right)\,.\]</span></p>
<p>Hence, a test statistic for <span class="math inline">\(H_0:\, \frac{1}{2}(\tau_A+\tau_B) - \frac{1}{2}(\tau_C+\tau_D)=0\)</span> is given by</p>
<p><span class="math display">\[
\frac{\frac{1}{2}(\bar{y}_{A.}+\bar{y}_{B.}) - \frac{1}{2}(\bar{y}_{C.}+\bar{y}_{D.})}{\sqrt{\frac{s^2}{4}\left(\frac{1}{n_A} + \frac{1}{n_B} + \frac{1}{n_C} + \frac{1}{n_D}\right)}} = \frac{2.685}{\frac{\sqrt{2.389}}{2}\sqrt{\frac{1}{7} + \frac{1}{8} + \frac{1}{9} + \frac{1}{6}}} = 4.70\,.
 \]</span></p>
<p>The critical value is <span class="math inline">\(t_{26, 1-0.05/2} = 2.0555\)</span>. Hence, we can reject <span class="math inline">\(H_0\)</span> and conclude there is a difference between brand-name and generic drugs.</p></li>
</ol>
</details>
<ol start="3" style="list-style-type: decimal">
<li><p><a id = "nap-black-ex"></a>The below table gives data from a completely randomised design to compare six different batches of hydrochloric acid on the yield of a dye (naphthalene black 12B).</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="crd.html#cb40-1" aria-hidden="true" tabindex="-1"></a>napblack <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">batch =</span> <span class="fu">rep</span>(<span class="fu">factor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>), <span class="fu">rep</span>(<span class="dv">5</span>, <span class="dv">6</span>)),</span>
<span id="cb40-2"><a href="crd.html#cb40-2" aria-hidden="true" tabindex="-1"></a>               <span class="at">repetition =</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">6</span>), </span>
<span id="cb40-3"><a href="crd.html#cb40-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">yield =</span> <span class="fu">c</span>(<span class="dv">145</span>, <span class="dv">40</span>, <span class="dv">40</span>, <span class="dv">120</span>, <span class="dv">180</span>, <span class="dv">140</span>, <span class="dv">155</span>, <span class="dv">90</span>, <span class="dv">160</span>, <span class="dv">95</span>,</span>
<span id="cb40-4"><a href="crd.html#cb40-4" aria-hidden="true" tabindex="-1"></a>                               <span class="dv">195</span>, <span class="dv">150</span>, <span class="dv">205</span>, <span class="dv">110</span>, <span class="dv">160</span>, <span class="dv">45</span>, <span class="dv">40</span>, <span class="dv">195</span>, <span class="dv">65</span>, <span class="dv">145</span>,</span>
<span id="cb40-5"><a href="crd.html#cb40-5" aria-hidden="true" tabindex="-1"></a>                               <span class="dv">195</span>, <span class="dv">230</span>, <span class="dv">115</span>, <span class="dv">235</span>, <span class="dv">225</span>, <span class="dv">120</span>, <span class="dv">55</span>, <span class="dv">50</span>, <span class="dv">80</span>, <span class="dv">45</span>)</span>
<span id="cb40-6"><a href="crd.html#cb40-6" aria-hidden="true" tabindex="-1"></a>                 )</span>
<span id="cb40-7"><a href="crd.html#cb40-7" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(</span>
<span id="cb40-8"><a href="crd.html#cb40-8" aria-hidden="true" tabindex="-1"></a>tidyr<span class="sc">::</span><span class="fu">pivot_wider</span>(napblack, <span class="at">names_from =</span> batch, <span class="at">values_from =</span> yield)[, <span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb40-9"><a href="crd.html#cb40-9" aria-hidden="true" tabindex="-1"></a> <span class="at">col.names =</span> <span class="fu">paste</span>(<span class="st">&quot;Batch&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>),</span>
<span id="cb40-10"><a href="crd.html#cb40-10" aria-hidden="true" tabindex="-1"></a> <span class="at">caption =</span> <span class="st">&quot;Naphthalene black experiment: yields (grams of standard colour) from six different batches of hydrochloric acid.&quot;</span></span>
<span id="cb40-11"><a href="crd.html#cb40-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<table>
<caption><span id="tab:nap-black">Table 2.3: </span>Naphthalene black experiment: yields (grams of standard colour) from six different batches of hydrochloric acid.</caption>
<thead>
<tr class="header">
<th align="right">Batch 1</th>
<th align="right">Batch 2</th>
<th align="right">Batch 3</th>
<th align="right">Batch 4</th>
<th align="right">Batch 5</th>
<th align="right">Batch 6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">145</td>
<td align="right">140</td>
<td align="right">195</td>
<td align="right">45</td>
<td align="right">195</td>
<td align="right">120</td>
</tr>
<tr class="even">
<td align="right">40</td>
<td align="right">155</td>
<td align="right">150</td>
<td align="right">40</td>
<td align="right">230</td>
<td align="right">55</td>
</tr>
<tr class="odd">
<td align="right">40</td>
<td align="right">90</td>
<td align="right">205</td>
<td align="right">195</td>
<td align="right">115</td>
<td align="right">50</td>
</tr>
<tr class="even">
<td align="right">120</td>
<td align="right">160</td>
<td align="right">110</td>
<td align="right">65</td>
<td align="right">235</td>
<td align="right">80</td>
</tr>
<tr class="odd">
<td align="right">180</td>
<td align="right">95</td>
<td align="right">160</td>
<td align="right">145</td>
<td align="right">225</td>
<td align="right">45</td>
</tr>
</tbody>
</table>
<p>Conduct a full analysis of this experiment, including</p>
<ol style="list-style-type: lower-alpha">
<li>exploratory data analysis;</li>
<li>fitting a linear model, and conducting an F-test to compare to a model that explains variation using the six batches to the null model;</li>
<li>usual linear model diagnostics;</li>
<li>multiple comparisons of all pairwise differences between treatments.</li>
</ol></li>
</ol>
<details>
<summary>
<b>Solution</b>
</summary>
<ol style="list-style-type: lower-alpha">
<li><p>Two of the simplest ways of examining the data are to calculate basic descriptive statistics, e.g. the mean and standard deviation of the yield in each batch, and to plot the data in the different batches using a simple graphical display, e.g. a stripchart of the yields in each batch. Notice that in both  and  we use the formula . This formula splits the data into groups defined by batch.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="crd.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">aggregate</span>(yield <span class="sc">~</span> batch, <span class="at">data =</span> napblack, <span class="at">FUN =</span> <span class="cf">function</span>(x) <span class="fu">c</span>(<span class="at">mean =</span> <span class="fu">mean</span>(x), </span>
<span id="cb41-2"><a href="crd.html#cb41-2" aria-hidden="true" tabindex="-1"></a>                                                          <span class="at">st.dev =</span> <span class="fu">sd</span>(x)))</span></code></pre></div>
<pre><code>##   batch yield.mean yield.st.dev
## 1     1     105.00        63.05
## 2     2     128.00        33.28
## 3     3     164.00        37.98
## 4     4      98.00        68.70
## 5     5     200.00        50.00
## 6     6      70.00        31.02</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="crd.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(yield <span class="sc">~</span> batch, <span class="at">data =</span> napblack)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:napblack-summary"></span>
<img src="bookdown_math3014-6027_files/figure-html/napblack-summary-1.png" alt="Naphthalene black experiment: distributions of dye yields from the six batches." width="672" />
<p class="caption">
Figure 2.2: Naphthalene black experiment: distributions of dye yields from the six batches.
</p>
</div>
<p>Notice that even within any particular batch, the number of grams of standard dyestuff colour determined by the dye trial varies from observation to observation. This <em>within-group</em> variation is considered to be random or residual variation. This cannot be explained by any differences between batches. However, a second source of variation in the overall data set can be explained by variation between the batches, i.e. between the different batch means themselves. We can see from the box plots (Figure <a href="crd.html#fig:napblack-summary">2.2</a>) and the mean yields in each batch that observations from batch number five appear to have given higher yields (in grams of standard colour) than those from the other batches.</p></li>
<li><p>When we fit linear models and compare them using analysis of variance (ANOVA), it enables us to decide whether the differences that seem to be evident in these simple plots and descriptive statistics are statistically significant or whether this kind of variation could have arisen by chance, even though there are no real differences between the batches.</p>
<p>An ANOVA table may be used to compare a linear model including differences between the batches to the null model. The linear model we will fit is a simple unit-treatment model:</p>
<p><span class="math display" id="eq:linmod">\[\begin{equation}
 Y_{ij} =  \mu +  \tau_i +  \varepsilon_{ij} \,,\qquad i=1,\ldots,6;~j=1,\ldots,5\,,
 \tag{2.13}
 \end{equation}\]</span></p>
<p>where <span class="math inline">\(Y_{ij}\)</span> is the response obtained from the <span class="math inline">\(j\)</span>th repetition of the <span class="math inline">\(i\)</span>th batch, <span class="math inline">\(\mu\)</span> is a constant term, <span class="math inline">\(\tau_i\)</span> is the expected effect due to the observation being in the <span class="math inline">\(k\)</span>th batch <span class="math inline">\((k=1,\ldots,5)\)</span> and <span class="math inline">\(\varepsilon_{ij}\)</span> are the random errors.</p>
<p>A test of the hypothesis that the group means are all equal is equivalent to a test that the <span class="math inline">\(\tau_i\)</span> are all equal to 0 <span class="math inline">\((H_0:\, \tau_1 = \tau_2 = \cdots = \tau_6 = 0)\)</span>. We can use <code>lm</code> to fit model <a href="crd.html#eq:linmod">(2.13)</a>, and <code>anova</code> to test the hypothesis. Before we fit the linear model, we need to make sure <code>batch</code> has type <code>factor</code><a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a>.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="crd.html#cb44-1" aria-hidden="true" tabindex="-1"></a>napblack<span class="sc">$</span>batch <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(napblack<span class="sc">$</span>batch)</span>
<span id="cb44-2"><a href="crd.html#cb44-2" aria-hidden="true" tabindex="-1"></a>napblack.lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(yield <span class="sc">~</span> batch, <span class="at">data =</span> napblack)</span>
<span id="cb44-3"><a href="crd.html#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(napblack.lm)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: yield
##           Df Sum Sq Mean Sq F value Pr(&gt;F)   
## batch      5  56358   11272     4.6 0.0044 **
## Residuals 24  58830    2451                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The p-value of 0.0044 indicates significant differences between at least two of the batch
means. Therefore <span class="math inline">\(H_0\)</span> is rejected and a suitable multiple comparison test should be carried
out.</p></li>
<li><p>To perform our analysis, we have fitted a linear model. Therefore, we should use some plots of the residuals <span class="math inline">\(y_{ij} - \hat{y}_{ij}\)</span> to check the model assumptions, particularly that the errors are independently and identically normally distributed. The function <code>rstandard</code> which produces residuals which have been standardised to have variance equal to 1.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="crd.html#cb46-1" aria-hidden="true" tabindex="-1"></a>standres <span class="ot">&lt;-</span> <span class="fu">rstandard</span>(napblack.lm)</span>
<span id="cb46-2"><a href="crd.html#cb46-2" aria-hidden="true" tabindex="-1"></a>fitted <span class="ot">&lt;-</span> <span class="fu">fitted</span>(napblack.lm)</span>
<span id="cb46-3"><a href="crd.html#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">pty =</span> <span class="st">&quot;s&quot;</span>)</span>
<span id="cb46-4"><a href="crd.html#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(napblack, {</span>
<span id="cb46-5"><a href="crd.html#cb46-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(batch, standres, <span class="at">xlab =</span> <span class="st">&quot;Batch&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Standarised residuals&quot;</span>)</span>
<span id="cb46-6"><a href="crd.html#cb46-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(fitted, standres, <span class="at">xlab =</span> <span class="st">&quot;Fitted value&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Standarised residuals&quot;</span>)</span>
<span id="cb46-7"><a href="crd.html#cb46-7" aria-hidden="true" tabindex="-1"></a>})</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:residuals"></span>
<img src="bookdown_math3014-6027_files/figure-html/residuals-1.png" alt="Residuals against batch (left) and fitted values (right) for the linear model fit to the naphthalene black data." width="100%" />
<p class="caption">
Figure 2.3: Residuals against batch (left) and fitted values (right) for the linear model fit to the naphthalene black data.
</p>
</div>
<p>The plots (Figure <a href="crd.html#fig:residuals">2.3</a>) show no large standardised residuals (<span class="math inline">\(&gt;2\)</span> in absolute value<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a>). While there is some evidence of unequal variation across batches, there is no obvious pattern with respect to fitted values (e.g. no “funnelling”).</p>
<p>We can also plot the standardised residuals against the quantiles of a standard normal distribution to assess the assumption of normality.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="crd.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">pty =</span> <span class="st">&quot;s&quot;</span>)</span>
<span id="cb47-2"><a href="crd.html#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(standres, <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:normalplot"></span>
<img src="bookdown_math3014-6027_files/figure-html/normalplot-1.png" alt="Normal probability plot for the standardised residuals for the linear model fit to the naphthalene black data." width="100%" />
<p class="caption">
Figure 2.4: Normal probability plot for the standardised residuals for the linear model fit to the naphthalene black data.
</p>
</div>
<p>The points lie quite well on a straight line (see Figure <a href="crd.html#fig:normalplot">2.4</a>), suggesting the assumption of normality is valid. Overall, the residual plots look reasonable; some investigation of transformations to correct for non-constant variance could be investigated (see MATH2010/STAT6123).</p></li>
<li><p>When a significant difference between the treatments has been indicated, the next stage is to try to determine which treatments differ. In some cases a specific difference is of interest, a control versus a new treatment for instance, in which case that difference could now be
inspected. However, usually no specific differences are to be considered a priori, and 
difference is of practical importance. A multiple comparison procedure is required to
investigate all possible differences, which takes account of the number of possible differences
available amongst the treatments (15 differences between the six batches here).</p>
<p>We will use Tukey’s method for controlling the experiment-wise type I error rate, fixed here at 5%, as implemented by <code>emmeans</code>.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="crd.html#cb48-1" aria-hidden="true" tabindex="-1"></a>napblack.emm <span class="ot">&lt;-</span> emmeans<span class="sc">::</span><span class="fu">emmeans</span>(napblack.lm, <span class="st">&#39;batch&#39;</span>)</span>
<span id="cb48-2"><a href="crd.html#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(napblack.emm)</span></code></pre></div>
<pre><code>##  contrast estimate   SE df t.ratio p.value
##  1 - 2         -23 31.3 24  -0.735  0.9755
##  1 - 3         -59 31.3 24  -1.884  0.4351
##  1 - 4           7 31.3 24   0.224  0.9999
##  1 - 5         -95 31.3 24  -3.034  0.0566
##  1 - 6          35 31.3 24   1.118  0.8692
##  2 - 3         -36 31.3 24  -1.150  0.8555
##  2 - 4          30 31.3 24   0.958  0.9266
##  2 - 5         -72 31.3 24  -2.299  0.2329
##  2 - 6          58 31.3 24   1.852  0.4535
##  3 - 4          66 31.3 24   2.108  0.3167
##  3 - 5         -36 31.3 24  -1.150  0.8555
##  3 - 6          94 31.3 24   3.002  0.0606
##  4 - 5        -102 31.3 24  -3.257  0.0348
##  4 - 6          28 31.3 24   0.894  0.9442
##  5 - 6         130 31.3 24   4.152  0.0043
## 
## P value adjustment: tukey method for comparing a family of 6 estimates</code></pre>
<p>We have two significant differences, between batches 4-5 and 5-6.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="crd.html#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">subset</span>(<span class="fu">transform</span>(<span class="fu">pairs</span>(napblack.emm)), p.value <span class="sc">&lt;</span> <span class="fl">0.05</span>)</span></code></pre></div>
<pre><code>##    contrast estimate    SE df t.ratio  p.value
## 13    4 - 5     -102 31.31 24  -3.257 0.034820
## 15    5 - 6      130 31.31 24   4.152 0.004295</code></pre></li>
</ol>
</details>
<ol start="4" style="list-style-type: decimal">
<li><span class="citation">(Adapted from <a href="#ref-Morris2011" role="doc-biblioref">Morris, 2011</a>)</span> Consider a completely randomised design with <span class="math inline">\(t = 5\)</span> treatments and <span class="math inline">\(n=50\)</span> units. The contrasts</li>
</ol>
<p><span class="math display">\[
\tau_2 - \tau_1, \quad \tau_3 - \tau_2, \quad \tau_4 - \tau_3, \tau_5 - \tau_4
\]</span></p>
<p>are of primary interest to the experimenter.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Find an allocation of the 50 units to the 5 treatments, i.e. find <span class="math inline">\(n_1, \ldots, n_5\)</span>, that minimises the average variance of the corresponding contrast estimators.</p></li>
<li><p>Fixing the proportions of experimental effort applied to each treatment to those found in part (a), i.e. to <span class="math inline">\(w_i = n_i/50\)</span>, find the value of <span class="math inline">\(n\)</span> required to make the ratio <span class="math inline">\(T = |\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}|/\sqrt{\mbox{var}\left(\widehat{\boldsymbol{c}^{\mathrm{T}}\boldsymbol{\tau}}\right)} = 2\)</span> assuming a signal-to-noise ratio of 1.</p></li>
</ol>
<details>
<summary>
<b>Solution</b>
</summary>
<ol style="list-style-type: lower-alpha">
<li><p>We can use the function <code>opt_ni</code> given in Section <a href="crd.html#crd-opt-all">2.8.1</a>:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="crd.html#cb52-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb52-2"><a href="crd.html#cb52-2" aria-hidden="true" tabindex="-1"></a>C <span class="ot">&lt;-</span> <span class="fu">matrix</span>(</span>
<span id="cb52-3"><a href="crd.html#cb52-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(</span>
<span id="cb52-4"><a href="crd.html#cb52-4" aria-hidden="true" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>,</span>
<span id="cb52-5"><a href="crd.html#cb52-5" aria-hidden="true" tabindex="-1"></a>  <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>,</span>
<span id="cb52-6"><a href="crd.html#cb52-6" aria-hidden="true" tabindex="-1"></a>  <span class="dv">0</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>,</span>
<span id="cb52-7"><a href="crd.html#cb52-7" aria-hidden="true" tabindex="-1"></a>  <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span></span>
<span id="cb52-8"><a href="crd.html#cb52-8" aria-hidden="true" tabindex="-1"></a>  ), <span class="at">nrow =</span> <span class="dv">4</span>, <span class="at">byrow =</span> T</span>
<span id="cb52-9"><a href="crd.html#cb52-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb52-10"><a href="crd.html#cb52-10" aria-hidden="true" tabindex="-1"></a><span class="fu">opt_ni</span>(C, n) </span></code></pre></div>
<pre><code>## [1]  8.009 11.327 11.327 11.327  8.009</code></pre>
<p>Rounding, we obtain a solution of the form <span class="math inline">\(n_1 = n_5 =8\)</span>, <span class="math inline">\(n_2 = n_4 = 11\)</span> and <span class="math inline">\(n_3 = 12\)</span>. Any of <span class="math inline">\(n_2, n_3, n_4\)</span> may be rounded up to 12 to form a design with the same variance.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="crd.html#cb54-1" aria-hidden="true" tabindex="-1"></a>nv <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">8</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">8</span>)</span>
<span id="cb54-2"><a href="crd.html#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="fu">crd_var</span>(C, nv <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb54-3"><a href="crd.html#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="fu">crd_var</span>(C, nv <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb54-4"><a href="crd.html#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="fu">crd_var</span>(C, nv <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span></code></pre></div>
<pre><code>## [1] 0.7803
## [1] 0.7803
## [1] 0.7803</code></pre></li>
<li><p>The optimal ratios for each treatment from part (a) are <span class="math inline">\(w_1 = w_5 = 0.1602\)</span> and <span class="math inline">\(w_2 = w_3 = w_4 = 0.2265\)</span>. Fixing these, we can use code from Section <a href="crd.html#crd-size">2.8.2</a> to find the required value of <span class="math inline">\(n\)</span> for each contrast.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="crd.html#cb56-1" aria-hidden="true" tabindex="-1"></a>nv <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb56-2"><a href="crd.html#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) nv[i] <span class="ot">&lt;-</span> <span class="fu">opt_n</span>(C[i, ], <span class="fu">opt_ni</span>(C, n) <span class="sc">/</span> n, <span class="dv">1</span>, <span class="dv">2</span>) <span class="co"># snr = 1, target = 2</span></span>
<span id="cb56-3"><a href="crd.html#cb56-3" aria-hidden="true" tabindex="-1"></a>nv</span></code></pre></div>
<pre><code>## [1] 42.63 35.31 35.31 42.63</code></pre>
<p>Hence, we need <span class="math inline">\(n = 43\)</span> for to achieve <span class="math inline">\(T = 2\)</span> for the first and last contrasts, and <span class="math inline">\(n = 36\)</span> for the second and third. The differences are due to the different proportions <span class="math inline">\(w_i\)</span> assumed for each treatment. To achieve <span class="math inline">\(T=2\)</span> for all contrasts, we pick the larger number, <span class="math inline">\(n = 43\)</span>.</p></li>
</ol>
</details>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Morris2011" class="csl-entry">
Morris, M. D. (2011) <em>Design of Experiments: An Introduction Based on Linear Models</em>. Boca Raton: <span>Chapman and Hall/CRC Press</span>.
</div>
<div id="ref-WH2009" class="csl-entry">
Wu, C. F. J. and Hamada, M. (2009) <em>Experiments: Planning, Analysis, and Parameter Design Optimization</em>. 2nd ed. New York: Wiley.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>In later chapters we will see examples where <span class="math inline">\(X_1\)</span> has <span class="math inline">\(&gt;1\)</span> columns, and hence <span class="math inline">\(X_1^{\mathrm{T}}X_1\)</span> is a matrix.<a href="crd.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>Often called “column centred”<a href="crd.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>If we recalled the material on “dummy” variables from MATH2010 or STAT6123, we would already have realised this.<a href="crd.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>That is, for any two solutions <span class="math inline">\(\tilde{\boldsymbol{\beta}}_1\)</span> and <span class="math inline">\(\tilde{\boldsymbol{\beta}}_2\)</span>, <span class="math inline">\(X\tilde{\boldsymbol{\beta}}_1 = \tilde{\boldsymbol{\beta}}_1\)</span>.<a href="crd.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>Recall that although <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\boldsymbol{\tau}\)</span> are not uniquely estimable, fitted values <span class="math inline">\(\hat{y}_i = \hat{\mu} + \hat{\tau}_i\)</span> <strong>are</strong>, and hence it does not matter which dummy variables we use in <code>lm</code>.<a href="crd.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>They aren’t, but it simplifies the maths!<a href="crd.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>So the experiment-wise type I error will actually be less than the prescribed <span class="math inline">\(\alpha\)</span><a href="crd.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>Given two independent samples <span class="math inline">\(u_1, \ldots, u_l\)</span> and <span class="math inline">\(v_1,\ldots,v_m\)</span> from the same distribution, the studentised range distribution is the distribution of <span class="math inline">\(\frac{R}{\sqrt{2}S}\)</span>, where <span class="math inline">\(R = u_{max}-u_{min}\)</span> is the range of the first sample, and <span class="math inline">\(S = \sqrt{\frac{1}{m-1}\sum_{i=1}^m(v_i - \bar{v})^2}\)</span> be the sample standard deviation of the second sample.<a href="crd.html#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>Factors are variables in <code>R</code> which take on a limited number of different values (e.g. categorical variables). We need to define a categorical variable, like <code>batch</code> as a <code>factor</code> to ensure they are treated correctly by functions such as <code>lm</code>.<a href="crd.html#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>We would anticipate 95% of the standardised residuals to lie in [-1.96, 1.96], as they will follow a standard normal distribution if the model assumptions are correct.<a href="crd.html#fnref17" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="blocking.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown_math3014-6027.pdf", "bookdown_math3014-6027.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
